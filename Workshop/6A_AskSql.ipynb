{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates retreiving information from SQL Databases using Azure OpenAI. The notebook is a part of the larger work on End-to-End virtual assisstant demo.\n",
    "\n",
    "**Background**\n",
    "\n",
    "We assume the role of a regional sales manager, who is interesed in learning more about Sales of different Surface products, price points etc. Information on sales is available across multiple tables in the SQL Database. In this notebook, we illustrate how to retrieve information available in SQL databases through natural language questioning. Specifically:\n",
    "\n",
    "1. We ask (sales related) questions in natural language\n",
    "2. Pass the question to Azure OpenAI as prompt. The completion we get in return is a SQL query to retrieve the answer\n",
    "3. We run this SQL query on our database to retrieve an answer\n",
    "4. Finally, we pass the question and (SQL retreived answer) to Azure OpenAI. The completion we get in return is the answer in natural language.\n",
    "\n",
    "For information on retreiving information from unstructured data or for the integrated demo, please refer to other material within the bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Packages\n",
    "import openai\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import time\n",
    "from Utilities.envVars import *\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up Azure OpenAI and SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chat_resouce():\n",
    "    '''\n",
    "    Setup Azure OpenAI\n",
    "    '''\n",
    "    API_KEY = OpenAiKey\n",
    "    RESOURCE_ENDPOINT = OpenAiEndPoint\n",
    "    API_VERSION = OpenAiVersion\n",
    "    \n",
    "    return API_KEY, RESOURCE_ENDPOINT, API_VERSION\n",
    "    \n",
    "def connect_sql_server(database):\n",
    "    '''\n",
    "    Setup SQL Server\n",
    "    '''\n",
    "    server = SynapseName\n",
    "    username = SynapseUser\n",
    "    password = SynapsePassword\n",
    "    cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "    cursor = cnxn.cursor()\n",
    "    \n",
    "    return cnxn\n",
    "\n",
    "\n",
    "def run_sql_query(completion):\n",
    "    '''\n",
    "    Function to run the generated SQL Query on SQL server and retrieve output.\n",
    "    Input: AOAI completion (SQL Query)\n",
    "    Output: Pandas dataframe containing results of the query run\n",
    "    \n",
    "    '''\n",
    "    cnxn = connect_sql_server(SynapsePool)\n",
    "    df = pd.read_sql(completion, cnxn)\n",
    "    return df\n",
    "\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = run_chat_resouce()[0]\n",
    "openai.api_base = run_chat_resouce()[1]\n",
    "openai.api_version = run_chat_resouce()[2]\n",
    "\n",
    "synapseConnectionString = \"Driver={{ODBC Driver 17 for SQL Server}};Server=tcp:{};\" \\\n",
    "                \"Database={};Uid={};Pwd={};Encrypt=yes;TrustServerCertificate=no;\" \\\n",
    "                \"Connection Timeout=30;\".format(SynapseName, SynapsePool, SynapseUser, SynapsePassword)\n",
    "params = urllib.parse.quote_plus(synapseConnectionString)\n",
    "sqlConnectionString = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the prompts to pass to Azure OpenAI for NL to SQL task. You find this prompt in **generate_nl_to_sql()**.\n",
    "\n",
    "*System Prompt*\n",
    "\n",
    "The first step is preparing the system prompt. This sets up the overall tone for GPT to answer Sales question. It also sets informs the bot the kind of questions it is authorized to answer.Following are some characteristics of our system prompt:\n",
    "1. We first generally describe the bots role (you are a SQL Programmer Assistant)\n",
    "2. We provide some additional details on the role:\n",
    "\n",
    "    a. Specify the SQL version to be used\n",
    "    \n",
    "    b. Insturctions for what to do if a valid query cannot be produced\n",
    "    \n",
    "    c. Instructions on what kind of questions to not answer\n",
    "    \n",
    "    d. Any other specific instruction.\n",
    "    \n",
    "    \n",
    "3. Since we are solving an NL to SQL problem, we need to provide the schema of the Sales database next. We provide column names along with datatypes, and relationship information by declaring primary and foreign keys\n",
    "4. Lastly, we provide some few shot examples. After experimentation on zero shot, few shot examples are added based on the types of queries we see most errors on. We make sure to pass these examples in the \"user\" and \"assistant\" role setup. \n",
    "\n",
    "*User Prompt*\n",
    "\n",
    "The next step is to prepare the user prompt. This is just the NL question to be asked. Make sure to follow some basic guidelines while phrasing questions:\n",
    "\n",
    "1. Be specific in what you are asking\n",
    "2. Make sure to phrase the question simply. Consider paraphrasing or breaking the question down into smaller segments in the question is involved.\n",
    "\n",
    "\n",
    "Our next prompt is to convert the query retreived answer into better format. You find this prompt in **generate_sql_to_nl()**\n",
    "\n",
    "*System Prompt*\n",
    "\n",
    "Since this is an easier task, the prompt is relatively simpler.\n",
    "\n",
    "1. Set the overall role for the bot\n",
    "2. Provide detailed instructions on the task to be performed (convert to natural language. Convert table to html table)\n",
    "3. provide guidance on what not to do (do not return markdown format)\n",
    "\n",
    "*User Prompt*\n",
    "\n",
    "The user prompt for this setup is just passing the original natural language question along with the SQL retreived answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "def executeQuery(query, limit=10000):  \n",
    "    engine = create_engine(sqlConnectionString)\n",
    "    result = pd.read_sql_query(query, engine)\n",
    "    result = result.infer_objects()\n",
    "    for col in result.columns:  \n",
    "        if 'date' in col.lower():  \n",
    "            result[col] = pd.to_datetime(result[col], errors=\"ignore\")  \n",
    "\n",
    "    if limit is not None:  \n",
    "        result = result.head(limit)  # limit to save memory  \n",
    "    # session.close()  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTableSchema():\n",
    "    sqlQuery = \"\"\"  \n",
    "    SELECT C.TABLE_NAME, C.COLUMN_NAME, C.DATA_TYPE, T.TABLE_TYPE, T.TABLE_SCHEMA  \n",
    "    FROM INFORMATION_SCHEMA.COLUMNS C  \n",
    "    JOIN INFORMATION_SCHEMA.TABLES T ON C.TABLE_NAME = T.TABLE_NAME AND C.TABLE_SCHEMA = T.TABLE_SCHEMA  \n",
    "    WHERE T.TABLE_TYPE = 'BASE TABLE'  \n",
    "    \"\"\"  \n",
    "    \n",
    "    # Execute the SQL query and store the results in a DataFrame  \n",
    "    #df = executeQuery(sqlQuery, limit=None)  \n",
    "    df = run_sql_query(sqlQuery)\n",
    "    output=[]\n",
    "    # Initialize variables to store table and column information  \n",
    "    curTable = ''  \n",
    "    columns = []  \n",
    "    \n",
    "    # Loop through the query results and output the table and column information  \n",
    "    for index, row in df.iterrows():\n",
    "        tableName = f\"{row['TABLE_SCHEMA']}.{row['TABLE_NAME']}\" \n",
    "        colName = row['COLUMN_NAME']  \n",
    "        dataType = row['DATA_TYPE']   \n",
    "        if \" \" in tableName:\n",
    "            tableName= f\"[{tableName}]\" \n",
    "        colName = row['COLUMN_NAME']  \n",
    "        if \" \" in colName:\n",
    "            colName= f\"[{colName}]\" \n",
    "\n",
    "        # If the table name has changed, output the previous table's information  \n",
    "        if curTable != tableName and curTable != '':  \n",
    "            output.append(f\"table: {curTable}, columns: {', '.join(columns)}\")\n",
    "            columns = []  \n",
    "        \n",
    "        # Add the current column information to the list of columns for the current table  \n",
    "        columns.append(f\"{colName} {dataType}\")  \n",
    "        \n",
    "        # Update the current table name  \n",
    "        curTable = tableName  \n",
    "    \n",
    "    # Output the last table's information  \n",
    "    output.append(f\"table: {curTable}, columns: {', '.join(columns)}\")\n",
    "    output = \"\\n \".join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astalati\\AppData\\Local\\Temp\\ipykernel_21820\\738049794.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(completion, cnxn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'table: dbo.CustomerCustomerDemo, columns: CustomerID nchar, CustomerTypeID nchar\\n table: dbo.CustomerDemographics, columns: CustomerTypeID nchar, CustomerDesc ntext\\n table: dbo.Region, columns: RegionID int, RegionDescription nchar\\n table: dbo.Territories, columns: TerritoryID nvarchar, TerritoryDescription nchar, RegionID int\\n table: dbo.EmployeeTerritories, columns: EmployeeID int, TerritoryID nvarchar\\n table: dbo.Employees, columns: EmployeeID int, LastName nvarchar, FirstName nvarchar, Title nvarchar, TitleOfCourtesy nvarchar, BirthDate datetime, HireDate datetime, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, HomePhone nvarchar, Extension nvarchar, Photo image, Notes ntext, ReportsTo int, PhotoPath nvarchar\\n table: dbo.Categories, columns: CategoryID int, CategoryName nvarchar, Description ntext, Picture image\\n table: dbo.Customers, columns: CustomerID nchar, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar\\n table: dbo.Shippers, columns: ShipperID int, CompanyName nvarchar, Phone nvarchar\\n table: dbo.Suppliers, columns: SupplierID int, CompanyName nvarchar, ContactName nvarchar, ContactTitle nvarchar, Address nvarchar, City nvarchar, Region nvarchar, PostalCode nvarchar, Country nvarchar, Phone nvarchar, Fax nvarchar, HomePage ntext\\n table: dbo.Orders, columns: OrderID int, CustomerID nchar, EmployeeID int, OrderDate datetime, RequiredDate datetime, ShippedDate datetime, ShipVia int, Freight money, ShipName nvarchar, ShipAddress nvarchar, ShipCity nvarchar, ShipRegion nvarchar, ShipPostalCode nvarchar, ShipCountry nvarchar\\n table: dbo.Products, columns: ProductID int, ProductName nvarchar, SupplierID int, CategoryID int, QuantityPerUnit nvarchar, UnitPrice money, UnitsInStock smallint, UnitsOnOrder smallint, ReorderLevel smallint, Discontinued bit\\n table: dbo.OrderDetails, columns: OrderID int, ProductID int, UnitPrice money, Quantity smallint, Discount real'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTableSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nl_to_sql(prompt_in, tableSchema, history = []):\n",
    "    '''\n",
    "    This GPT4 engine is setup for NLtoSQL tasks on the Sales DB.\n",
    "    Input: NL question related to sales\n",
    "    Output: SQL query to run on the sales database\n",
    "    '''\n",
    "\n",
    "    sysPrompt = f\"\"\" You are a SQL programmer Assistant.Your role is to generate SQL code (SQL Server) to retrieve an answer to a natural language query. Make sure to disambiguate column names when creating queries that use more than one table. If a valid SQL query cannot be generated, only say \"ERROR:\" followed by why it cannot be generated.\n",
    "                  Do not answer any questions on inserting or deleting rows from the table. Instead, say \"ERROR: I am not authorized to make changes to the data\"\n",
    "\n",
    "                  Use the following sales database schema to write SQL queries:\n",
    "                  {tableSchema}\n",
    "\n",
    "                  Examples:\n",
    "                  User: Which Shipper can ship the product?. SQL Code:\n",
    "                  Assistant: SELECT s.ShipperID, s.CompanyName FROM Shippers s JOIN Orders o ON s.ShipperID = o.ShipVia JOIN OrderDetails od ON o.OrderID = od.OrderID JOIN Products p ON od.ProductID = p.ProductID;\n",
    "                  User: Number of units in stock by category and supplier continent? SQL Code:\n",
    "                  Assistant: SELECT c.CategoryName, s.Country AS SupplierContinent, SUM(p.UnitsInStock) AS TotalUnitsInStock FROM Products p JOIN Categories c ON p.CategoryID = c.CategoryID JOIN Suppliers s ON p.SupplierID = s.SupplierID GROUP BY c.CategoryName, s.Country ORDER BY c.CategoryName, s.Country;\n",
    "                  User: List Top 10 Products?. SQL Code:\n",
    "                  Assistant: SELECT TOP 10 Products from Products;\n",
    "            \"\"\"\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": sysPrompt}\n",
    "        ]\n",
    "\n",
    "    messages.extend(history)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_in})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"chat16k\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=2000,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "def generate_sql_to_nl(prompt_in):\n",
    "    '''\n",
    "    This GPT4 engine is setup for SQLtoNL tasks on the Sales DB.\n",
    "    Input: Original question asked. Answer retreived from running SQL query.\n",
    "    Output: Natural language sentence(s).\n",
    "    '''\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"chat16k\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are bot that takes question-answer pairs and converts the answer to natural language. For tabular information return it as an html table. Do not return markdown format.\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_in},\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=2000,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequent cells, we demonstrate the setup in action. We first try out a simple question. Next, we try out a more involved question, which looks at information from multiple tables. Lastly, we see a multi-turn question i.e a question which requires context from the question previously asked.\n",
    "\n",
    "**Handling Multi-turn questions in prompts**\n",
    "\n",
    "In some cases, the user breaks down the question in two multiple parts as the conversation continues. In this case, GPT would require context from the history to be able to comprehend and correctly answer the current question. As a result, we add this extra information to the prompt before sending our current question. Specifically, \n",
    "1. We first append our conversation history to the prompt. We keep the \"user\", \"assistant\" format we have been following so far with our prompt. Within \"user\", we add the qustion asked in \"user\", and the NL answer recieved in \"assistant\". Make sure to keep the order of Q&A as it occured in the conversation.\n",
    "2. Finally, we add our current question to the prompt, and pass this newly updated prompt to generate_nl_to_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Products - A simple NLtoSQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our user input is the NL question, as an output, Azure OpenAI generates as completion the SQL query we should run on the Sales database to answer this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astalati\\AppData\\Local\\Temp\\ipykernel_21820\\738049794.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(completion, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ProductName, UnitPrice\n",
      "FROM Products;\n"
     ]
    }
   ],
   "source": [
    "question_products = 'List our all products with their prices.'\n",
    "tableSchema = getTableSchema()\n",
    "completion_products = generate_nl_to_sql(question_products,tableSchema)\n",
    "print(completion_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the SQL query on our database. We retrive the information as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astalati\\AppData\\Local\\Temp\\ipykernel_2688\\738049794.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(completion, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ProductName  UnitPrice\n",
      "0                              Chai      18.00\n",
      "1                             Chang      19.00\n",
      "2                     Aniseed Syrup      10.00\n",
      "3      Chef Anton's Cajun Seasoning      22.00\n",
      "4            Chef Anton's Gumbo Mix      21.35\n",
      "..                              ...        ...\n",
      "72                       Röd Kaviar      15.00\n",
      "73                    Longlife Tofu      10.00\n",
      "74             Rhönbräu Klosterbier       7.75\n",
      "75                     Lakkalikööri      18.00\n",
      "76  Original Frankfurter grüne Soße      13.00\n",
      "\n",
      "[77 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "sql_output_products = run_sql_query(completion_products)\n",
    "print(sql_output_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask OpenAI to convert this into a more \"Chat-setting friendly\" answer. We pass the question, and the answer to Azure OpenAI and ask it to convert the informtaion to an HTML table. In case of a non table asnwer, We ask Azure OpenAI to convert the answer to natural language format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <tr>\n",
      "    <th>ProductName</th>\n",
      "    <th>UnitPrice</th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chai</td>\n",
      "    <td>18.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chang</td>\n",
      "    <td>19.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Aniseed Syrup</td>\n",
      "    <td>10.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chef Anton's Cajun Seasoning</td>\n",
      "    <td>22.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chef Anton's Gumbo Mix</td>\n",
      "    <td>21.35</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Grandma's Boysenberry Spread</td>\n",
      "    <td>25.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Uncle Bob's Organic Dried Pears</td>\n",
      "    <td>30.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Northwoods Cranberry Sauce</td>\n",
      "    <td>40.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mishi Kobe Niku</td>\n",
      "    <td>97.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Ikura</td>\n",
      "    <td>31.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Queso Cabrales</td>\n",
      "    <td>21.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Queso Manchego La Pastora</td>\n",
      "    <td>38.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Konbu</td>\n",
      "    <td>6.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Tofu</td>\n",
      "    <td>23.25</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Genen Shouyu</td>\n",
      "    <td>15.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Pavlova</td>\n",
      "    <td>17.45</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Alice Mutton</td>\n",
      "    <td>39.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Carnarvon Tigers</td>\n",
      "    <td>62.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Teatime Chocolate Biscuits</td>\n",
      "    <td>9.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Sir Rodney's Marmalade</td>\n",
      "    <td>81.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Sir Rodney's Scones</td>\n",
      "    <td>10.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gustaf's Knäckebröd</td>\n",
      "    <td>21.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Tunnbröd</td>\n",
      "    <td>9.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Guaraná Fantástica</td>\n",
      "    <td>4.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>NuNuCa Nuß-Nougat-Creme</td>\n",
      "    <td>14.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gumbär Gummibärchen</td>\n",
      "    <td>31.23</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Schoggi Schokolade</td>\n",
      "    <td>43.9</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Rössle Sauerkraut</td>\n",
      "    <td>45.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Thüringer Rostbratwurst</td>\n",
      "    <td>123.79</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Nord-Ost Matjeshering</td>\n",
      "    <td>25.89</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gorgonzola Telino</td>\n",
      "    <td>12.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mascarpone Fabioli</td>\n",
      "    <td>32.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Geitost</td>\n",
      "    <td>2.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Sasquatch Ale</td>\n",
      "    <td>14.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Steeleye Stout</td>\n",
      "    <td>18.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Inlagd Sill</td>\n",
      "    <td>19.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gravad lax</td>\n",
      "    <td>26.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Côte de Blaye</td>\n",
      "    <td>263.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chartreuse verte</td>\n",
      "    <td>18.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Boston Crab Meat</td>\n",
      "    <td>18.4</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Jack's New England Clam Chowder</td>\n",
      "    <td>9.65</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Singaporean Hokkien Fried Mee</td>\n",
      "    <td>14.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Ipoh Coffee</td>\n",
      "    <td>46.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gula Malacca</td>\n",
      "    <td>19.45</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Rogede sild</td>\n",
      "    <td>9.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Spegesild</td>\n",
      "    <td>12.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Zaanse koeken</td>\n",
      "    <td>9.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chocolade</td>\n",
      "    <td>12.75</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Maxilaku</td>\n",
      "    <td>20.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Valkoinen suklaa</td>\n",
      "    <td>16.25</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Manjimup Dried Apples</td>\n",
      "    <td>53.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Filo Mix</td>\n",
      "    <td>7.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Perth Pasties</td>\n",
      "    <td>32.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Tourtière</td>\n",
      "    <td>7.45</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Pâté chinois</td>\n",
      "    <td>24.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gnocchi di nonna Alice</td>\n",
      "    <td>38.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Ravioli Angelo</td>\n",
      "    <td>19.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Escargots de Bourgogne</td>\n",
      "    <td>13.25</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Raclette Courdavault</td>\n",
      "    <td>55.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Camembert Pierrot</td>\n",
      "    <td>34.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Sirop d'érable</td>\n",
      "    <td>28.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Tarte au sucre</td>\n",
      "    <td>49.3</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Vegie-spread</td>\n",
      "    <td>43.9</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Wimmers gute Semmelknödel</td>\n",
      "    <td>33.25</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Louisiana Fiery Hot Pepper Sauce</td>\n",
      "    <td>21.05</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Louisiana Hot Spiced Okra\n"
     ]
    }
   ],
   "source": [
    "nl_output = generate_sql_to_nl(str(question_products +  str(sql_output_products.to_dict('list')) ))\n",
    "print(nl_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2:  Sales - Example of Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(DISTINCT CustomerID) AS TotalCustomers FROM Orders;\n"
     ]
    }
   ],
   "source": [
    "question_sales = 'How many customers did placed an order?'\n",
    "completion_sales = generate_nl_to_sql(question_sales, tableSchema)\n",
    "print(completion_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astalati\\AppData\\Local\\Temp\\ipykernel_2688\\738049794.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(completion, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TotalCustomers\n",
      "0              89\n"
     ]
    }
   ],
   "source": [
    "sql_output_sales = run_sql_query(completion_sales)\n",
    "print(sql_output_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 89 customers who placed an order.\n"
     ]
    }
   ],
   "source": [
    "nl_output = generate_sql_to_nl(str(question_sales +  str(sql_output_sales.to_dict('list')) ))\n",
    "print(nl_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Stock - Example of Multi Turn questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT p.ProductName, SUM(od.UnitPrice * od.Quantity) AS TotalSales\n",
      "FROM Products p\n",
      "JOIN OrderDetails od ON p.ProductID = od.ProductID\n",
      "GROUP BY p.ProductName;\n"
     ]
    }
   ],
   "source": [
    "question_stock = 'List the total sales grouped by product'\n",
    "completion_stock = generate_nl_to_sql(question_stock, tableSchema)\n",
    "print(completion_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astalati\\AppData\\Local\\Temp\\ipykernel_2688\\738049794.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(completion, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ProductName  TotalSales\n",
      "0                      Alice Mutton     35482.2\n",
      "1                     Aniseed Syrup      3080.0\n",
      "2                  Boston Crab Meat     19048.3\n",
      "3                 Camembert Pierrot     50286.0\n",
      "4                  Carnarvon Tigers     31987.5\n",
      "..                              ...         ...\n",
      "72  Uncle Bob's Organic Dried Pears     22464.0\n",
      "73                 Valkoinen suklaa      3510.0\n",
      "74                     Vegie-spread     17696.3\n",
      "75        Wimmers gute Semmelknödel     23009.0\n",
      "76                    Zaanse koeken      4358.6\n",
      "\n",
      "[77 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "sql_output_stock = run_sql_query(completion_stock)\n",
    "print(sql_output_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <tr>\n",
      "    <th>ProductName</th>\n",
      "    <th>TotalSales</th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Alice Mutton</td>\n",
      "    <td>35482.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Aniseed Syrup</td>\n",
      "    <td>3080.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Boston Crab Meat</td>\n",
      "    <td>19048.3</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Camembert Pierrot</td>\n",
      "    <td>50286.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Carnarvon Tigers</td>\n",
      "    <td>31987.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chai</td>\n",
      "    <td>14277.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chang</td>\n",
      "    <td>18559.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chartreuse verte</td>\n",
      "    <td>13150.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chef Anton's Cajun Seasoning</td>\n",
      "    <td>9424.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chef Anton's Gumbo Mix</td>\n",
      "    <td>5801.15</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Chocolade</td>\n",
      "    <td>1542.75</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Côte de Blaye</td>\n",
      "    <td>149984.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Escargots de Bourgogne</td>\n",
      "    <td>6664.75</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Filo Mix</td>\n",
      "    <td>3383.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Flotemysost</td>\n",
      "    <td>20876.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Geitost</td>\n",
      "    <td>1713.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Genen Shouyu</td>\n",
      "    <td>1813.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gnocchi di nonna Alice</td>\n",
      "    <td>45121.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gorgonzola Telino</td>\n",
      "    <td>16172.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Grandma's Boysenberry Spread</td>\n",
      "    <td>7345.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gravad lax</td>\n",
      "    <td>3047.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Guaraná Fantástica</td>\n",
      "    <td>4782.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gudbrandsdalsost</td>\n",
      "    <td>24307.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gula Malacca</td>\n",
      "    <td>10524.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gumbär Gummibärchen</td>\n",
      "    <td>21534.9</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Gustaf's Knäckebröd</td>\n",
      "    <td>7232.4</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Ikura</td>\n",
      "    <td>22140.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Inlagd Sill</td>\n",
      "    <td>14542.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Ipoh Coffee</td>\n",
      "    <td>25079.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Jack's New England Clam Chowder</td>\n",
      "    <td>9098.1</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Konbu</td>\n",
      "    <td>5234.4</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Lakkalikööri</td>\n",
      "    <td>16794.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Laughing Lumberjack Lager</td>\n",
      "    <td>2562.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Longlife Tofu</td>\n",
      "    <td>2566.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Louisiana Fiery Hot Pepper Sauce</td>\n",
      "    <td>14607.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Louisiana Hot Spiced Okra</td>\n",
      "    <td>3519.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Manjimup Dried Apples</td>\n",
      "    <td>44742.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mascarpone Fabioli</td>\n",
      "    <td>9171.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Maxilaku</td>\n",
      "    <td>9500.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mishi Kobe Niku</td>\n",
      "    <td>8827.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Mozzarella di Giovanni</td>\n",
      "    <td>25738.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Nord-Ost Matjeshering</td>\n",
      "    <td>14775.54</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Northwoods Cranberry Sauce</td>\n",
      "    <td>13760.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>NuNuCa Nuß-Nougat-Creme</td>\n",
      "    <td>4051.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Original Frankfurter grüne Soße</td>\n",
      "    <td>9685.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Outback Lager</td>\n",
      "    <td>11472.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Pâté chinois</td>\n",
      "    <td>19512.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Pavlova</td>\n",
      "    <td>18748.05</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Perth Pasties</td>\n",
      "    <td>21510.2</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Queso Cabrales</td>\n",
      "    <td>13902.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Queso Manchego La Pastora</td>\n",
      "    <td>12866.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Raclette Courdavault</td>\n",
      "    <td>76296.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Ravioli Angelo</td>\n",
      "    <td>7807.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Rhönbräu Klosterbier</td>\n",
      "    <td>8650.55</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Röd Kaviar</td>\n",
      "    <td>4200.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Rogede sild</td>\n",
      "    <td>4740.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Rössle Sauerkraut</td>\n",
      "    <td>26865.6</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Sasquatch Ale</td>\n",
      "    <td>6678.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Schoggi Schokolade</td>\n",
      "    <td>15231.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Scottish Longbreads</td>\n",
      "    <td>9362.5</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Singaporean Hokkien Fried Mee</td>\n",
      "    <td>9332.4</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Sir Rodney's Marmalade</td>\n",
      "    <td>23635.8</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Sir Rodney's Scones</td>\n",
      "    <td>9636.0</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <\n"
     ]
    }
   ],
   "source": [
    "nl_output = generate_sql_to_nl(str(question_stock +  str(sql_output_stock.to_dict('list')) ))\n",
    "print(nl_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'List the total sales grouped by product'},\n",
       " {'role': 'system',\n",
       "  'content': \"<table>\\n  <tr>\\n    <th>ProductName</th>\\n    <th>TotalSales</th>\\n  </tr>\\n  <tr>\\n    <td>Alice Mutton</td>\\n    <td>35482.2</td>\\n  </tr>\\n  <tr>\\n    <td>Aniseed Syrup</td>\\n    <td>3080.0</td>\\n  </tr>\\n  <tr>\\n    <td>Boston Crab Meat</td>\\n    <td>19048.3</td>\\n  </tr>\\n  <tr>\\n    <td>Camembert Pierrot</td>\\n    <td>50286.0</td>\\n  </tr>\\n  <tr>\\n    <td>Carnarvon Tigers</td>\\n    <td>31987.5</td>\\n  </tr>\\n  <tr>\\n    <td>Chai</td>\\n    <td>14277.6</td>\\n  </tr>\\n  <tr>\\n    <td>Chang</td>\\n    <td>18559.2</td>\\n  </tr>\\n  <tr>\\n    <td>Chartreuse verte</td>\\n    <td>13150.8</td>\\n  </tr>\\n  <tr>\\n    <td>Chef Anton's Cajun Seasoning</td>\\n    <td>9424.8</td>\\n  </tr>\\n  <tr>\\n    <td>Chef Anton's Gumbo Mix</td>\\n    <td>5801.15</td>\\n  </tr>\\n  <tr>\\n    <td>Chocolade</td>\\n    <td>1542.75</td>\\n  </tr>\\n  <tr>\\n    <td>Côte de Blaye</td>\\n    <td>149984.2</td>\\n  </tr>\\n  <tr>\\n    <td>Escargots de Bourgogne</td>\\n    <td>6664.75</td>\\n  </tr>\\n  <tr>\\n    <td>Filo Mix</td>\\n    <td>3383.8</td>\\n  </tr>\\n  <tr>\\n    <td>Flotemysost</td>\\n    <td>20876.5</td>\\n  </tr>\\n  <tr>\\n    <td>Geitost</td>\\n    <td>1713.5</td>\\n  </tr>\\n  <tr>\\n    <td>Genen Shouyu</td>\\n    <td>1813.5</td>\\n  </tr>\\n  <tr>\\n    <td>Gnocchi di nonna Alice</td>\\n    <td>45121.2</td>\\n  </tr>\\n  <tr>\\n    <td>Gorgonzola Telino</td>\\n    <td>16172.5</td>\\n  </tr>\\n  <tr>\\n    <td>Grandma's Boysenberry Spread</td>\\n    <td>7345.0</td>\\n  </tr>\\n  <tr>\\n    <td>Gravad lax</td>\\n    <td>3047.2</td>\\n  </tr>\\n  <tr>\\n    <td>Guaraná Fantástica</td>\\n    <td>4782.6</td>\\n  </tr>\\n  <tr>\\n    <td>Gudbrandsdalsost</td>\\n    <td>24307.2</td>\\n  </tr>\\n  <tr>\\n    <td>Gula Malacca</td>\\n    <td>10524.2</td>\\n  </tr>\\n  <tr>\\n    <td>Gumbär Gummibärchen</td>\\n    <td>21534.9</td>\\n  </tr>\\n  <tr>\\n    <td>Gustaf's Knäckebröd</td>\\n    <td>7232.4</td>\\n  </tr>\\n  <tr>\\n    <td>Ikura</td>\\n    <td>22140.2</td>\\n  </tr>\\n  <tr>\\n    <td>Inlagd Sill</td>\\n    <td>14542.6</td>\\n  </tr>\\n  <tr>\\n    <td>Ipoh Coffee</td>\\n    <td>25079.2</td>\\n  </tr>\\n  <tr>\\n    <td>Jack's New England Clam Chowder</td>\\n    <td>9098.1</td>\\n  </tr>\\n  <tr>\\n    <td>Konbu</td>\\n    <td>5234.4</td>\\n  </tr>\\n  <tr>\\n    <td>Lakkalikööri</td>\\n    <td>16794.0</td>\\n  </tr>\\n  <tr>\\n    <td>Laughing Lumberjack Lager</td>\\n    <td>2562.0</td>\\n  </tr>\\n  <tr>\\n    <td>Longlife Tofu</td>\\n    <td>2566.0</td>\\n  </tr>\\n  <tr>\\n    <td>Louisiana Fiery Hot Pepper Sauce</td>\\n    <td>14607.0</td>\\n  </tr>\\n  <tr>\\n    <td>Louisiana Hot Spiced Okra</td>\\n    <td>3519.0</td>\\n  </tr>\\n  <tr>\\n    <td>Manjimup Dried Apples</td>\\n    <td>44742.6</td>\\n  </tr>\\n  <tr>\\n    <td>Mascarpone Fabioli</td>\\n    <td>9171.2</td>\\n  </tr>\\n  <tr>\\n    <td>Maxilaku</td>\\n    <td>9500.0</td>\\n  </tr>\\n  <tr>\\n    <td>Mishi Kobe Niku</td>\\n    <td>8827.0</td>\\n  </tr>\\n  <tr>\\n    <td>Mozzarella di Giovanni</td>\\n    <td>25738.8</td>\\n  </tr>\\n  <tr>\\n    <td>Nord-Ost Matjeshering</td>\\n    <td>14775.54</td>\\n  </tr>\\n  <tr>\\n    <td>Northwoods Cranberry Sauce</td>\\n    <td>13760.0</td>\\n  </tr>\\n  <tr>\\n    <td>NuNuCa Nuß-Nougat-Creme</td>\\n    <td>4051.6</td>\\n  </tr>\\n  <tr>\\n    <td>Original Frankfurter grüne Soße</td>\\n    <td>9685.0</td>\\n  </tr>\\n  <tr>\\n    <td>Outback Lager</td>\\n    <td>11472.0</td>\\n  </tr>\\n  <tr>\\n    <td>Pâté chinois</td>\\n    <td>19512.0</td>\\n  </tr>\\n  <tr>\\n    <td>Pavlova</td>\\n    <td>18748.05</td>\\n  </tr>\\n  <tr>\\n    <td>Perth Pasties</td>\\n    <td>21510.2</td>\\n  </tr>\\n  <tr>\\n    <td>Queso Cabrales</td>\\n    <td>13902.0</td>\\n  </tr>\\n  <tr>\\n    <td>Queso Manchego La Pastora</td>\\n    <td>12866.8</td>\\n  </tr>\\n  <tr>\\n    <td>Raclette Courdavault</td>\\n    <td>76296.0</td>\\n  </tr>\\n  <tr>\\n    <td>Ravioli Angelo</td>\\n    <td>7807.8</td>\\n  </tr>\\n  <tr>\\n    <td>Rhönbräu Klosterbier</td>\\n    <td>8650.55</td>\\n  </tr>\\n  <tr>\\n    <td>Röd Kaviar</td>\\n    <td>4200.0</td>\\n  </tr>\\n  <tr>\\n    <td>Rogede sild</td>\\n    <td>4740.5</td>\\n  </tr>\\n  <tr>\\n    <td>Rössle Sauerkraut</td>\\n    <td>26865.6</td>\\n  </tr>\\n  <tr>\\n    <td>Sasquatch Ale</td>\\n    <td>6678.0</td>\\n  </tr>\\n  <tr>\\n    <td>Schoggi Schokolade</td>\\n    <td>15231.5</td>\\n  </tr>\\n  <tr>\\n    <td>Scottish Longbreads</td>\\n    <td>9362.5</td>\\n  </tr>\\n  <tr>\\n    <td>Singaporean Hokkien Fried Mee</td>\\n    <td>9332.4</td>\\n  </tr>\\n  <tr>\\n    <td>Sir Rodney's Marmalade</td>\\n    <td>23635.8</td>\\n  </tr>\\n  <tr>\\n    <td>Sir Rodney's Scones</td>\\n    <td>9636.0</td>\\n  </tr>\\n  <tr>\\n    <\"}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = []\n",
    "history.append({\"role\": \"user\",\"content\": question_stock})\n",
    "history.append({\"role\": \"system\",\"content\":nl_output})\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT p.ProductName, SUM(od.Quantity) AS TotalSales\n",
      "FROM Products p\n",
      "JOIN OrderDetails od ON p.ProductID = od.ProductID\n",
      "JOIN Orders o ON od.OrderID = o.OrderID\n",
      "WHERE p.ProductName = 'Vegie-spread'\n",
      "GROUP BY p.ProductName;\n"
     ]
    }
   ],
   "source": [
    "question_stock_2 = 'How much of that is for Vegie-spread?'\n",
    "completion_stock_2 = generate_nl_to_sql(question_stock_2, tableSchema, history)\n",
    "print(completion_stock_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astalati\\AppData\\Local\\Temp\\ipykernel_2688\\738049794.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(completion, cnxn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ProductName  TotalSales\n",
      "0  Vegie-spread         445\n"
     ]
    }
   ],
   "source": [
    "sql_output_stock_2 = run_sql_query(completion_stock_2)\n",
    "print(sql_output_stock_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sales for Vegie-spread is 445.\n"
     ]
    }
   ],
   "source": [
    "nl_output = generate_sql_to_nl(str(question_stock_2 +  str(sql_output_stock_2.to_dict('list'))))\n",
    "print(nl_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
