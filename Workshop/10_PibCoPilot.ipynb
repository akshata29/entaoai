{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIB CoPilot\n",
    "PIBs are also used to create a pitchbook by assessing a company's strategy, competitive positioning, review of financial statements, industry dynamics, and trends within the industry. \n",
    "1. Company Overview and Executive Bio - A brief description of the company and its key executives with biographies.\n",
    "2. Conference calls: The same day a company issues its quarterly press release, it will also hold a conference call. On the call, analysts often learn details about management guidance. These conference calls are transcribed by several service providers and can be accessed by subscribers of large financial data providers.\n",
    "3. Press Release: Can be found in the investor relations section of most companies' websites and contains the financial statements which are used in forms 10-K and 10-Q. \n",
    "4. News: News articles that may affect a company's stock price or growth prospect would be something that analysts look into, particularly within a 6-12 month time horizon.\n",
    "5. SEC filings: These regulatory documents require a company to file Form 10-K and Form 10-Q with the SEC on an ongoing basis. Form 10-K is a financial overview and commentary for the last year, usually found on the company's website. Form 10-Q is similar to form 10-K, but it is a report for the last quarter instead of the previous year.\n",
    "6. Equity research reports: Look into key forecasts for metrics like Revenue, EBITDA, and EPS for the company or competing firms to form a consensus estimate. \n",
    "7. Investor Presentations: Companies provide historical information as an important foundation from which forecasts are made to guide key forecasting drivers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0 -  Pre-requsite and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "from Utilities.envVars import *\n",
    "import uuid\n",
    "# Set Search Service endpoint, index name, and API key from environment variables\n",
    "indexName = SearchIndex\n",
    "\n",
    "# Set OpenAI API key and endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OpenAiVersion\n",
    "openai_api_key = OpenAiKey\n",
    "assert openai_api_key, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = openai_api_key\n",
    "openAiEndPoint = f\"https://{OpenAiService}.openai.azure.com\"\n",
    "assert openAiEndPoint, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in openAiEndPoint.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = openAiEndPoint\n",
    "davincimodel = OpenAiDavinci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embeddingModelType = \"azureopenai\"\n",
    "temperature = 0\n",
    "tokenLength = 1000\n",
    "symbol = 'NTRS'\n",
    "apikey = FmpKey\n",
    "os.environ['BING_SUBSCRIPTION_KEY'] = BingKey\n",
    "os.environ['BING_SEARCH_URL'] = BingUrl\n",
    "pibIndexName = 'pibdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms.openai import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, HTML\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "from Utilities.pibCopilot import indexDocs, createPressReleaseIndex, createStockNewsIndex, mergeDocs, createPibIndex, findPibData, findEarningCalls, deletePibData, performEarningCallCogSearch\n",
    "from Utilities.pibCopilot import indexEarningCallSections, createEarningCallVectorIndex, createEarningCallIndex, performCogSearch, createSecFilingIndex, findSecFiling\n",
    "from Utilities.pibCopilot import findLatestSecFilings, createSecFilingsVectorIndex, indexSecFilingsSections\n",
    "import typing\n",
    "from Utilities.fmp import *\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexibility to change the call to OpenAI or Azure OpenAI\n",
    "if (embeddingModelType == 'azureopenai'):\n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_key = OpenAiKey\n",
    "    openai.api_version = OpenAiVersion\n",
    "    openai.api_base = OpenAiBase\n",
    "\n",
    "    llm = AzureOpenAI(deployment_name=OpenAiDavinci,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=OpenAiKey,\n",
    "            max_tokens=tokenLength,\n",
    "            batch_size=10, \n",
    "            max_retries=12)\n",
    "    \n",
    "    llmChat = AzureChatOpenAI(\n",
    "                openai_api_base=openai.api_base,\n",
    "                openai_api_version=OpenAiVersion,\n",
    "                deployment_name=OpenAiChat16k,\n",
    "                temperature=temperature,\n",
    "                openai_api_key=OpenAiKey,\n",
    "                openai_api_type=\"azure\",\n",
    "                max_tokens=tokenLength)\n",
    "    \n",
    "    logging.info(\"LLM Setup done\")\n",
    "    embeddings = OpenAIEmbeddings(deployment=OpenAiEmbedding, chunk_size=1, openai_api_key=OpenAiKey)\n",
    "elif embeddingModelType == \"openai\":\n",
    "    openai.api_type = \"open_ai\"\n",
    "    openai.api_base = \"https://api.openai.com/v1\"\n",
    "    openai.api_version = '2020-11-07' \n",
    "    openai.api_key = OpenAiApiKey\n",
    "    llm = OpenAI(temperature=temperature,\n",
    "            openai_api_key=OpenAiApiKey,\n",
    "            max_tokens=tokenLength)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)\n",
    "\n",
    "    llmChat = ChatOpenAI(temperature=temperature,\n",
    "        openai_api_key=OpenAiApiKey,\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        max_tokens=tokenLength)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OpenAiApiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "central = timezone('US/Central')\n",
    "today = datetime.now(central)\n",
    "currentYear = today.year\n",
    "historicalDate = today - relativedelta(years=3)\n",
    "historicalYear = historicalDate.year\n",
    "historicalDate = historicalDate.strftime(\"%Y-%m-%d\")\n",
    "totalYears = currentYear - historicalYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find CIK based on Symbol\n",
    "cik = str(int(searchCik(apikey=apikey, ticker=symbol)[0][\"companyCik\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbol: str = \"AAPL\"\n",
    "#cik = \"320193\"\n",
    "#symbols: typing.List[str] = [\"AAPL\", \"CSCO\", \"QQQQ\"]\n",
    "#exchange: str = \"NYSE\"\n",
    "#exchanges: typing.List[str] = [\"NYSE\", \"NASDAQ\"]\n",
    "#query: str = \"AA\"\n",
    "#limit: int = 3\n",
    "#period: str = \"quarter\"\n",
    "#download: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'73124'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletePibData(SearchService, SearchKey, pibIndexName, \"73124\", \"4\", returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                       'pibData'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Paid Data - Company Profile and Key Executives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index pibdata already exists\n",
      "[{'id': '13a57088-22bf-41dc-83d6-ef0fecddfac8', 'symbol': 'NTRS', 'cik': '73124', 'step': '1', 'description': 'Biography of Key Executives', 'insertedDate': '2023-07-26', 'pibData': '[{\\'name\\': \\'Mr. Steven L. Fradkin\\', \\'title\\': \\'Executive Vice President & Pres of Wealth Management\\', \\'biography\\': \\'Steven L. Fradkin is the President of the Wealth Management business unit at Northern Trust. He has been with the company since 1985 and has served on the Management Committee since 2004. Fradkin has a background in economics and has completed the Program for Management Development at Harvard Business School. He is also involved in various organizations and has a strong leadership background.\\'}, {\\'name\\': \\'Ms. Susan Cohen Levy J.D.\\', \\'title\\': \\'Executive Vice President & Gen. Counsel\\', \\'biography\\': \\'The summary includes information about various individuals, such as Susan J. Cohen, Jon Foster, Kamala Harris, Philip O. Ozuah, Susan Crown, Silvia M. Ferretti, Steve Inman, Rachel Ogden, Devora Cohen-Karni, Jeanneane Maxon, Julia Cohen-LÃ©vy, Susan Donegan, Dr. Marisa T. Cohen, Dr. Susan L. Cohn, Steven and Susan Beebe, Susan Cohen (film producer), Leonard Cohen, and William Sebastian Cohen. The summary mentions their professional roles, achievements, and affiliations.\\'}, {\\'name\\': \\'Mr. Ian  Headon\\', \\'title\\': \\'Head of Depositary Regulatory & Technical Services\\', \\'biography\\': \\'The summary is not clear as it contains a mixture of information about Ian Headon, the state of the Irish funds industry, the potential impact of Brexit, and tips on writing a biography.\\'}, {\\'name\\': \"Mr. Michael G. O\\'Grady\", \\'title\\': \\'Chairman & Chief Executive Officer\\', \\'biography\\': \"The summary includes information about various individuals named Michael O\\'Grady, including their positions and roles in different organizations. It also mentions the salary of Mr. Grady at Northern Trust. Additionally, it briefly mentions other topics such as writing a biography, professional templates, and the difference between autobiography and memoir.\"}, {\\'name\\': \\'Mr. Thomas A. South\\', \\'title\\': \\'Executive Vice President & Chief Information Officer\\', \\'biography\\': \\'The text discusses the importance of writing a short bio for professional purposes and highlights the qualities that should be included in an executive bio. It also mentions the roles and responsibilities of various executives in different companies. Additionally, it provides information about the net worth of Thomas A. South and explains the difference between a CEO and a president in a company. The text also briefly mentions the role of a vice president and the salary of an executive vice president.\\'}, {\\'name\\': \\'Briar  Rose\\', \\'title\\': \\'Vice President of Investor Relations\\', \\'biography\\': \\'The legend of Briar Rose, a hidden castle, and a sleeping princess spreads, attracting many princes who are killed by the briar. After 100 years, a new prince ignores the warnings and goes to the castle. The story of Briar Rose is a fairy tale/folk tale published in 1905 by the Grimm Brothers. The protagonist of Briar Rose is Becca Berlin, who learns the story from her grandmother Gemma. Gemma reveals that she is Briar Rose on her deathbed and asks Becca to find the castle, the prince, and the maker of the spells. Briar Rose is a young adult novel written by Jane Yolen and incorporates elements of Sleeping Beauty. It won the Mythopoeic Fantasy Award for Adult Literature in 1993. The Legend of Briar Rose is a series of paintings by Edward Burne-Jones completed between 1885 and 1890.\\'}, {\\'name\\': \\'Mr. Jason Jerrome Tyler\\', \\'title\\': \\'Executive Vice President & Chief Financial Officer\\', \\'biography\\': \"The summary includes information about prominent historians and conservation experts discussing the architectural relevance of various buildings. It also mentions the Chief Financial Officer of Northern Trust Corporation, Jason Tyler, and provides information about his background and affiliations. Additionally, it mentions other executives and their roles in different companies. The summary briefly touches on the responsibilities of a CFO and an executive vice president. It also mentions a boxing match and provides a definition of a CEO. The summary concludes by mentioning the importance of business titles and corporate roles in a company\\'s success.\"}, {\\'name\\': \\'Mr. Jim  Ward\\', \\'title\\': \\'Senior Investment Officer & Sr. Vice President of Western Michigan Office\\', \\'biography\\': \\'Jim Ward has been appointed as the Senior Investment Officer and Senior Vice President at Northern Trust in the Western Michigan Office. He will lead the investment team in providing advice to high net worth clients and institutions. Ward brings over 35 years of investment experience to this role and previously worked at Fifth Third Bank. He has also held leadership positions at ProVest and IBM. Additionally, Ward recently transitioned from the role of chairman to president of the Truckload Carriers Association.\\'}, {\\'name\\': \\'Mr. Peter B. Cherecwich\\', \\'title\\': \\'Executive Vice President & Pres of Asset Servicing\\', \\'biography\\': \"The summary is about Peter B. Cherecwich, who is the President of Asset Servicing at Northern Trust Corporation. It mentions his involvement in AI, machine learning, and automation, and emphasizes the importance of high-quality data for these technologies. The summary also includes information about Cherecwich\\'s positions, compensation, and education. Additionally, it briefly mentions Northern Trust Corporation as a leading provider of wealth management, asset servicing, asset management, and banking services.\"}, {\\'name\\': \"Mr. Michael Gerard O\\'Grady\", \\'title\\': \\'Chairman & Chief Executive Officer\\', \\'biography\\': \"The summary is a collection of various information about different individuals named Michael Gerhardt, Michael O\\'Grady, Gerard O\\'Grady, and Gerard Xavier Marcel Depardieu. It includes their professional backgrounds, positions, and achievements in different fields such as constitutional law, finance, healthcare, and acting. The summary also mentions their affiliations with organizations like Northern Trust Corp and their educational backgrounds.\"}, {\\'name\\': \\'K. Kelly Mannard\\', \\'title\\': \\'Chief Marketing & Communications Officer\\', \\'biography\\': \\'Kelly Mannard is the Executive Vice President, Chief Strategy and Marketing Officer at Northern Trust. She is highly respected and has extensive knowledge and foresight in her field. She has held various executive positions within the company and is currently responsible for defining and aligning strategy across business units and functional teams. Additionally, she serves as the Chief Marketing and Communications Officer. Northern Trust recently appointed Shana Hayes as Director of Community Affairs, who will report to Mannard.\\'}, {\\'name\\': \\'Jennifer  Childe C.F.A.\\', \\'title\\': \\'Senior Vice President & Director of Investor Relations\\', \\'biography\\': \\'Jennifer Childe has joined Northern Trust as Director of Investor Relations, succeeding Mark Bette. She brings over 20 years of experience in investor relations, ESG, and Wall Street. Childe previously held positions at CNO Financial Group and Clermont Partners. She is known for her appearances on CNNfn and CNBC and has been quoted in publications such as The Wall Street Journal and Fortune. Childe will work closely with Bette during the transition.\\'}, {\\'name\\': \\'Ms. Alexandria  Taylor\\', \\'title\\': \\'Executive Vice President & Chief HR Officer\\', \\'biography\\': \\'The text includes various mentions of different individuals named Alexandria Taylor, Kamala Harris, Alexandria Ocasio-Cortez, and others. It also discusses the importance of writing a short bio and an executive bio. Additionally, it mentions the work and achievements of different individuals in various fields such as politics, law, and healthcare.\\'}, {\\'name\\': \\'Alexandria  Taylor\\', \\'title\\': \\'Executive Vice President & Chief HR Officer\\', \\'biography\\': \\'The summary is about various topics including company information, the importance of writing a short bio, executive bios, the salary of executive vice presidents, and the roles of vice presidents and chief operating officers in a company. It also mentions Alexandria Taylor, a candidate for judge, and provides information about presidents and their biographies.\\'}]'}, {'id': '6ecd357a-c235-4572-8cfa-b7dec74c2d31', 'symbol': 'NTRS', 'cik': '73124', 'step': '1', 'description': 'Company Profile', 'insertedDate': '2023-07-26', 'pibData': \"[{'symbol': 'NTRS', 'mktCap': 16636108700, 'companyName': 'Northern Trust Corporation', 'currency': 'USD', 'cik': '0000073124', 'isin': 'US6658591044', 'exchange': 'NASDAQ Global Select', 'industry': 'Asset Management', 'sector': 'Financial Services', 'address': '50 South La Salle Street', 'city': 'Chicago', 'state': 'IL', 'zip': '60603', 'website': 'https://www.northerntrust.com', 'description': 'Northern Trust Corporation, a financial holding company, provides wealth management, asset servicing, asset management, and banking solutions for corporations, institutions, families, and individuals worldwide. It operates in two segments, Asset Servicing and Wealth Management. The Asset Servicing segment offers asset servicing and related services, including custody, fund administration, investment operations outsourcing, investment management, investment risk and analytical services, employee benefit services, securities lending, foreign exchange, treasury management, brokerage services, transition management services, banking, and cash management services. This segment serves corporate and public retirement funds, foundations, endowments, fund managers, insurance companies, sovereign wealth funds, and other institutional investors. The Wealth Management segment offers trust, investment management, custody, and philanthropic; financial consulting; guardianship and estate administration; family business consulting; family financial education; brokerage services; and private and business banking services. This segment serves high-net-worth individuals and families, business owners, executives, professionals, retirees, and established privately held businesses. The company also provides asset management services, such as active and passive equity; active and passive fixed income; cash management; alternative asset classes comprising private equity and hedge funds of funds; and multi-manager advisory services and products through separately managed accounts, bank common and collective funds, registered investment companies, exchange traded funds, non-U.S. collective investment funds, and unregistered private investment funds. In addition, it offers overlay and other risk management services. Northern Trust Corporation was founded in 1889 and is headquartered in Chicago, Illinois.'}]\"}]\n"
     ]
    }
   ],
   "source": [
    "# Get the information about the company and list of all executives.\n",
    "# Check if we have already created record for Profile\n",
    "createPibIndex(SearchService, SearchKey, pibIndexName)\n",
    "step = \"1\"\n",
    "s1Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "if r.get_count() == 0:\n",
    "    step1Profile = []\n",
    "    profile = companyProfile(apikey=apikey, symbol=symbol)\n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(profile))\n",
    "    sData = {\n",
    "            'id' : str(uuid.uuid4()),\n",
    "            'symbol': symbol,\n",
    "            'cik': cik,\n",
    "            'step': step,\n",
    "            'description': 'Company Profile',\n",
    "            'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "            'pibData' : str(df[['symbol', 'mktCap', 'companyName', 'currency', 'cik', 'isin', 'exchange', 'industry', 'sector', 'address', 'city', 'state', 'zip', 'website', 'description']].to_dict('records'))\n",
    "    }\n",
    "    step1Profile.append(sData)\n",
    "    s1Data.append(sData)\n",
    "    # Insert data into pibIndex\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, step1Profile)\n",
    "\n",
    "    # Get the list of all executives and generate biography for each of them\n",
    "    executives = keyExecutives(apikey=apikey, symbol=symbol)\n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(executives),orient='columns')\n",
    "    df = df.drop_duplicates(subset='name', keep=\"first\")\n",
    "\n",
    "    step1Biography = []\n",
    "    tools = []\n",
    "    topK = 1\n",
    "    step1Executives = []\n",
    "    #### With the company profile and key executives, we can ask Bing Search to get the biography of the all Key executives and \n",
    "    # ask OpenAI to summarize it - Public Data\n",
    "    for executive in executives:\n",
    "        name = executive['name']\n",
    "        title = executive['title']\n",
    "        query = f\"Give me brief biography of {name} who is {title} at {symbol}. Biography should be restricted to {symbol} and summarize it as 2 paragraphs.\"\n",
    "        qaPromptTemplate = \"\"\"\n",
    "            Rephrase the following question asked by user to perform intelligent internet search\n",
    "            {query}\n",
    "            \"\"\"\n",
    "        optimizedPrompt = qaPromptTemplate.format(query=query)\n",
    "        qaPrompt = PromptTemplate(input_variables=[\"query\"],template=qaPromptTemplate)\n",
    "        chain = LLMChain(llm=llmChat, prompt=qaPrompt)\n",
    "        q = chain.run(query=query)\n",
    "        # completion = openai.Completion.create(\n",
    "        #             engine=OpenAiDavinci,\n",
    "        #             prompt=optimizedPrompt,\n",
    "        #             temperature=temperature,\n",
    "        #             max_tokens=100,\n",
    "        #             n=1)\n",
    "        # q = completion.choices[0].text\n",
    "        bingSearch = BingSearchAPIWrapper(k=20)\n",
    "        results = bingSearch.run(query=q)\n",
    "        chain = load_summarize_chain(llmChat, chain_type=\"stuff\")\n",
    "        docs = [Document(page_content=results)]\n",
    "        summary = chain.run(docs)\n",
    "        step1Executives.append({\n",
    "            \"name\": name,\n",
    "            \"title\": title,\n",
    "            \"biography\": summary\n",
    "        })\n",
    "\n",
    "    sData = {\n",
    "            'id' : str(uuid.uuid4()),\n",
    "            'symbol': symbol,\n",
    "            'cik': cik,\n",
    "            'step': step,\n",
    "            'description': 'Biography of Key Executives',\n",
    "            'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "            'pibData' : str(step1Executives)\n",
    "    }\n",
    "    step1Biography.append(sData)\n",
    "    s1Data.append(sData)\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, step1Biography)\n",
    "else:\n",
    "    for s in r:\n",
    "        s1Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "\n",
    "print(s1Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Paid Data -  Get the Earnings Call Transcript for each quarter for last 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index earningcalls already exists\n",
      "Found 1 records for NTRS for 2 2023\n"
     ]
    }
   ],
   "source": [
    "# Call the paid data (FMP) API\n",
    "# Get the earning call transcripts for the last 3 years and merge documents into the index.\n",
    "i = 0\n",
    "earningsData = []\n",
    "step = \"2\"\n",
    "earningIndexName = 'earningcalls'\n",
    "# Create the index if it does not exist\n",
    "createEarningCallIndex(SearchService, SearchKey, earningIndexName)\n",
    "# Get the list of all earning calls available\n",
    "earningCallDates = earningCallsAvailableDates(apikey=apikey, symbol=symbol)\n",
    "quarter = earningCallDates[0][0]\n",
    "year = earningCallDates[0][1]\n",
    "r = findEarningCalls(SearchService, SearchKey, earningIndexName, symbol, str(quarter), str(year), returnFields=['id', 'symbol', \n",
    "            'quarter', 'year', 'callDate', 'content'])\n",
    "if r.get_count() == 0:\n",
    "    insertEarningCall = []\n",
    "    earningTranscript = earningCallTranscript(apikey=apikey, symbol=symbol, year=str(year), quarter=quarter)\n",
    "    for transcript in earningTranscript:\n",
    "        symbol = transcript['symbol']\n",
    "        quarter = transcript['quarter']\n",
    "        year = transcript['year']\n",
    "        callDate = transcript['date']\n",
    "        content = transcript['content']\n",
    "        todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "        id = f\"{symbol}-{year}-{quarter}\"\n",
    "        earningRecord = {\n",
    "            \"id\": id,\n",
    "            \"symbol\": symbol,\n",
    "            \"quarter\": str(quarter),\n",
    "            \"year\": str(year),\n",
    "            \"callDate\": callDate,\n",
    "            \"content\": content,\n",
    "            #\"inserteddate\": datetime.now(central).strftime(\"%Y-%m-%d\"),\n",
    "        }\n",
    "        earningsData.append(earningRecord)\n",
    "        insertEarningCall.append(earningRecord)\n",
    "        mergeDocs(SearchService, SearchKey, earningIndexName, insertEarningCall)\n",
    "else:\n",
    "    print(f\"Found {r.get_count()} records for {symbol} for {quarter} {year}\")\n",
    "    for s in r:\n",
    "        earningsData.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'quarter': s['quarter'],\n",
    "                'year': s['year'],\n",
    "                'callDate': s['callDate'],\n",
    "                'content': s['content']\n",
    "            })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the transcripts as per Split Method, Chunk Size and Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last earning call transcripts was on : 2023-07-19 14:56:03\n",
      "Number of documents chunks generated from Call transcript :  8\n"
     ]
    }
   ],
   "source": [
    "# Let's just use the latest earnings call transcript to create the documents that we want to use it for generative AI tasks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=1000)\n",
    "\n",
    "print(\"Last earning call transcripts was on :\", earningsData[-1]['callDate'])\n",
    "rawDocs = splitter.create_documents([earningsData[-1]['content']])\n",
    "docs = splitter.split_documents(rawDocs)\n",
    "print(\"Number of documents chunks generated from Call transcript : \", len(docs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the vector store embedding data for chunked sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index latestearningcalls already exists\n",
      "Total docs: 8\n",
      "Found 8 sections for NTRS 2023 Q2\n",
      "Already indexed 8 sections for NTRS 2023 Q2\n"
     ]
    }
   ],
   "source": [
    "# Store the last index of the earning call transcript in vector Index\n",
    "earningVectorIndexName = 'latestearningcalls'\n",
    "createEarningCallVectorIndex(SearchService, SearchKey, earningVectorIndexName)\n",
    "\n",
    "indexEarningCallSections(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey,\n",
    "                         embeddingModelType, OpenAiEmbedding, earningVectorIndexName, docs,\n",
    "                         earningsData[-1]['callDate'], earningsData[-1]['symbol'], earningsData[-1]['year'],\n",
    "                         earningsData[-1]['quarter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAnswer(chainType, topK, symbol, quarter, year, question, indexName, llm):\n",
    "    r = performEarningCallCogSearch(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey, embeddingModelType, \n",
    "        OpenAiEmbedding, symbol, str(quarter), str(year), question, indexName, topK, returnFields=['id', 'symbol', 'quarter', 'year', 'callDate', 'content'])\n",
    "    \n",
    "    if r == None:\n",
    "        docs = [Document(page_content=\"No results found\")]\n",
    "    else :\n",
    "        docs = [\n",
    "            Document(page_content=doc['content'], metadata={\"id\": doc['id'], \"source\": ''})\n",
    "            for doc in r\n",
    "            ]\n",
    "    \n",
    "    if chainType == \"map_reduce\":\n",
    "        # Prompt for MapReduce\n",
    "        qaTemplate = \"\"\"Use the following portion of a long document to see if any of the text is relevant to answer the question.\n",
    "                Return any relevant text.\n",
    "                {context}\n",
    "                Question: {question}\n",
    "                Relevant text, if any :\"\"\"\n",
    "\n",
    "        qaPrompt = PromptTemplate(\n",
    "            template=qaTemplate, input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        combinePromptTemplate = \"\"\"Given the following extracted parts of a long document and a question, create a final answer.\n",
    "        If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "        If the answer is not contained within the text below, say \\\"I don't know\\\".\n",
    "\n",
    "        QUESTION: {question}\n",
    "        =========\n",
    "        {summaries}\n",
    "        =========\n",
    "        \"\"\"\n",
    "        combinePrompt = PromptTemplate(\n",
    "            template=combinePromptTemplate, input_variables=[\"summaries\", \"question\"]\n",
    "        )\n",
    "\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, question_prompt=qaPrompt, \n",
    "                                            combine_prompt=combinePrompt, \n",
    "                                            return_intermediate_steps=True)\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question})\n",
    "        outputAnswer = answer['output_text']\n",
    "\n",
    "    elif chainType == \"stuff\":\n",
    "    # Prompt for ChainType = Stuff\n",
    "        template = \"\"\"\n",
    "                Given the following extracted parts of a long document and a question, create a final answer. \n",
    "                If you don't know the answer, just say that you don't know. Don't try to make up an answer. \n",
    "                If the answer is not contained within the text below, say \\\"I don't know\\\".\n",
    "\n",
    "                QUESTION: {question}\n",
    "                =========\n",
    "                {summaries}\n",
    "                =========\n",
    "                \"\"\"\n",
    "        qaPrompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, prompt=qaPrompt)\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "        outputAnswer = answer['output_text']\n",
    "    elif chainType == \"default\":\n",
    "        # Default Prompt\n",
    "        qaChain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")\n",
    "        answer = qaChain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "        outputAnswer = answer['output_text']\n",
    "\n",
    "    return outputAnswer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top questions to ask during earning call - Let's see if we can find the answers to these questions in the transcripts\n",
    "- What are some of the current and looming threats to the business?\n",
    "- What is the debt level or debt ratio of the company right now?\n",
    "- How do you feel about the upcoming product launches or new products?\n",
    "- How are you managing or investing in your human capital?\n",
    "- How do you track the trends in your industry?\n",
    "- Are there major slowdowns in the production of goods?\n",
    "- How will you maintain or surpass this performance in the next few quarters?\n",
    "- What will your market look like in five years as a result of using your product or service?\n",
    "- How are you going to address the risks that will affect the long-term growth of the company?\n",
    "- How is the performance this quarter going to affect the long-term goals of the company?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another specific question to ask\n",
    "- Revenue: Provide key information about revenue for the quarter\n",
    "- Profitability: Provide key information about profits and losses (P&L) for the quarter\n",
    "- Industry Trends: Provide key information about industry trends for the quarter\n",
    "- Trend: Provide key information about business trends discussed on the call\n",
    "- Risk: Provide key information about risk discussed on the call\n",
    "- AI: Provide key information about AI discussed on the call\n",
    "- M&A: Provide any information about mergers and acquisitions (M&A) discussed on the call.\n",
    "- Guidance: Provide key information about guidance discussed on the call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we have the lastest transcripts in the document format, let's summarize the information with following specific summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data\n",
      "[{'id': 'e7f70c99-15c0-49be-b278-38afe69add4f', 'symbol': 'NTRS', 'cik': '73124', 'step': '2', 'description': 'Earning Call Summary', 'insertedDate': '2023-07-26', 'pibData': '[{\\'summary\\': \"Northern Trust Corporation reported solid sequential performance in the second quarter of 2023, with trust fees and assets under custody and management increasing. Net interest income was down slightly due to higher funding costs. The wealth management business saw modest growth in assets under custody and management and trust fees, particularly in higher wealth tiers and the global family office segment. The company also saw strong flows into its institutional money market platform and won key mandates in asset management. In asset servicing, Northern Trust had good momentum in core custody and fund administration, particularly in Europe. The company\\'s balance sheet remains strong with ample capital and liquidity. Northern Trust is focused on rationalizing its cost base and improving expense growth. The company expects its new business momentum to continue and is well positioned to support clients and generate value for stakeholders in the second half of the year.\"}]'}, {'id': 'dde0ec4c-f9f2-4c49-8225-50d98bc21a34', 'symbol': 'NTRS', 'cik': '73124', 'step': '2', 'description': 'Earning Call Q&A', 'insertedDate': '2023-07-26', 'pibData': '[{\\'question\\': \\'Provide key information about profits and losses (P&L) for the quarter\\', \\'answer\\': \\'The key information about profits and losses (P&L) for the quarter is as follows:\\\\n\\\\n- Net income for the second quarter was $332 million.\\\\n- Earnings per share for the second quarter were $1.56.\\\\n- The return on average common equity was 12.4%.\\\\n- Revenue was up 1% on a sequential quarter basis and down 1% over the prior year.\\\\n- Expenses were down 1% on a sequential quarter basis and up 5% over the prior year.\\\\n- Pretax income was up 13% sequentially, but down 9% over the prior year.\\\\n\\\\nPlease note that this information is based on the provided content and may not include all relevant details.\\'}, {\\'question\\': \\'1. Financial Results\\', \\'answer\\': \\' Northern Trust Corporation reported solid sequential performance in the second quarter of 2023. Net income was $332 million, with earnings per share of $1.56. Revenue increased by 1% sequentially but decreased by 1% compared to the previous year. Expenses were down 1% sequentially but up 5% compared to the previous year. Assets under custody and administration for asset servicing clients increased by 2% sequentially and 5% year-over-year. Assets under management for asset servicing clients increased by 3% sequentially and 4% year-over-year. Assets under management for wealth management clients increased by 2% sequentially and 7% year-over-year. Net interest income was $525 million, down 4% sequentially but up 12% from the previous year. Noninterest expenses were $1.3 billion, 4% higher sequentially and 9% higher than the previous year.\\'}, {\\'question\\': \\'2. Business Highlights\\', \\'answer\\': \" The wealth management business saw modest growth, particularly in higher wealth tiers and the global family office segment. In asset management, there were strong flows into the institutional money market platform and key mandates were won across products. Asset servicing also had good momentum, particularly in core custody and fund administration. Northern Trust\\'s balance sheet remains strong, and they are focused on rationalizing their cost base and driving sustainable improvements. They are well positioned for the second half of the year.\"}, {\\'question\\': \\'3. Future Outlook\\', \\'answer\\': \\' The company expects deposit outflows to continue, especially in August, due to unpredictable client behavior resulting from rapid rate hikes. They are focused on expense control and expect operating expenses to grow more modestly. Capital ratios remain strong, and the company returned $257 million to common shareholders through dividends and stock repurchases. They aim to achieve a pretax margin in the 30s and are working towards their target expense-to-trust ratio. The company plans to shift the mix of their investment portfolio to protect net interest income in the context of potential future rate hikes.\\'}, {\\'question\\': \\'4. Business Risks\\', \\'answer\\': \\' The company has experienced unpredictable client behavior due to rapid rate hikes, leading to deposit outflows. Noninterest expenses were higher compared to the previous year, with compensation and technology expenses being the highest areas of spending. The overall outlook for commercial real estate has worsened, although there have been improvements in a small number of borrowers in the credit portfolio. The company halted a project in asset servicing due to cost and financial targets not being met.\\'}, {\\'question\\': \\'5. Management Positive Sentiment\\', \\'answer\\': \" Management is confident about the growth in the wealth management business, particularly in higher wealth tiers and the global family office segment. They are also pleased with the strong flows into the institutional money market platform and the winning of key mandates across products in asset management. Asset servicing has good momentum, particularly in core custody and fund administration. The company\\'s balance sheet remains strong, and they are focused on rationalizing their cost base and driving sustainable improvements.\"}, {\\'question\\': \\'6. Management Negative Sentiment\\', \\'answer\\': \\' Management is concerned about the unpredictable client behavior resulting from rapid rate hikes, leading to deposit outflows. They are also cautious about the worsening outlook for commercial real estate and the need to protect net interest income in the context of potential future rate hikes. The company has halted a project in asset servicing due to cost and financial targets not being met. There may be upward pressure on expenses in the second half of the year due to delayed projects in equipment and software.\\'}]'}]\n"
     ]
    }
   ],
   "source": [
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "earningCallQa = []\n",
    "s2Data = []\n",
    "if r.get_count() == 0:\n",
    "    commonQuestions = [\n",
    "        \"What are some of the current and looming threats to the business?\",\n",
    "        \"What is the debt level or debt ratio of the company right now?\",\n",
    "        \"How do you feel about the upcoming product launches or new products?\",\n",
    "        \"How are you managing or investing in your human capital?\",\n",
    "        \"How do you track the trends in your industry?\",\n",
    "        \"Are there major slowdowns in the production of goods?\",\n",
    "        \"How will you maintain or surpass this performance in the next few quarters?\",\n",
    "        \"What will your market look like in five years as a result of using your product or service?\",\n",
    "        \"How are you going to address the risks that will affect the long-term growth of the company?\",\n",
    "        \"How is the performance this quarter going to affect the long-term goals of the company?\"\n",
    "    ]\n",
    "\n",
    "    for question in commonQuestions:\n",
    "        answer = findAnswer('stuff', 3, symbol, quarter, year, question, earningVectorIndexName, llmChat)\n",
    "        if \"I don't know\" not in answer:\n",
    "            earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    commonQuestions = [\n",
    "            \"Provide key information about revenue for the quarter\",\n",
    "            \"Provide key information about profits and losses (P&L) for the quarter\",\n",
    "            \"Provide key information about industry trends for the quarter\",\n",
    "            \"Provide key information about business trends discussed on the call\",\n",
    "            \"Provide key information about risk discussed on the call\",\n",
    "            \"Provide key information about AI discussed on the call\",\n",
    "            \"Provide any information about mergers and acquisitions (M&A) discussed on the call.\",\n",
    "            \"Provide key information about guidance discussed on the call\"\n",
    "        ]\n",
    "\n",
    "    for question in commonQuestions:\n",
    "        answer = findAnswer('stuff', 3, symbol, quarter, year, question, earningVectorIndexName, llmChat)\n",
    "        if \"I don't know\" not in answer:\n",
    "            earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    promptTemplate = \"\"\"You are an AI assistant tasked with summarizing financial information from earning call transcript. \n",
    "            Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "            Please generate a concise and comprehensive summary between 5-7 paragraphs on each of the following numbered topics.  Your response should include the topic as part of the summary.\n",
    "            1. Financial Results: Please provide a summary of the financial results.\n",
    "            2. Business Highlights: Please provide a summary of the business highlights.\n",
    "            3. Future Outlook: Please provide a summary of the future outlook.\n",
    "            4. Business Risks: Please provide a summary of the business risks.\n",
    "            5. Management Positive Sentiment: Please provide a summary of the what management is confident about.\n",
    "            6. Management Negative Sentiment: Please provide a summary of the what management is concerned about.\n",
    "            Please remember to use clear language and maintain the integrity of the original information without missing any important details:\n",
    "            {text}\n",
    "            \"\"\"\n",
    "    customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "    chainType = \"map_reduce\"\n",
    "    summaryChain = load_summarize_chain(llmChat, chain_type=chainType, return_intermediate_steps=False, \n",
    "                                combine_prompt=customPrompt)\n",
    "    summaryOutput = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "\n",
    "    output = summaryOutput['output_text']\n",
    "    formattedOutput = output.splitlines()\n",
    "    while(\"\" in formattedOutput):\n",
    "        formattedOutput.remove(\"\")\n",
    "    for summary in formattedOutput:\n",
    "        splitSummary = summary.split(\":\")\n",
    "        try:\n",
    "            question = splitSummary[0]\n",
    "            answer = splitSummary[1]\n",
    "            earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    s2Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Earning Call Q&A',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(earningCallQa)\n",
    "        })\n",
    "    \n",
    "    promptTemplate = \"\"\"You are an AI assistant tasked with summarizing financial information from earning call transcript. \n",
    "        Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "        Please generate a concise and comprehensive summary between 5-7 paragraphs and maintain the continuity.  \n",
    "        Ensure your summary includes the key information from the transcript like future outlook, business risk, \n",
    "        management concerns.\n",
    "        {text}\n",
    "        \"\"\"\n",
    "    customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "    try:\n",
    "        chainType = \"stuff\"\n",
    "        summaryChain = load_summarize_chain(llmChat, chain_type=chainType, prompt=customPrompt)\n",
    "        summaryOutput = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "        output = summaryOutput['output_text']\n",
    "    except:\n",
    "        chainType = \"map_reduce\"\n",
    "        summaryChain = load_summarize_chain(llmChat, chain_type=chainType, combine_prompt=customPrompt)\n",
    "        summaryOutput = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "        output = summaryOutput['output_text']\n",
    "    s2Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Earning Call Summary',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str([{\"summary\": output}])\n",
    "    })\n",
    "\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s2Data)\n",
    "else:\n",
    "    print('Found existing data')\n",
    "    for s in r:\n",
    "        s2Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "        \n",
    "print(s2Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                    'pibData'])\n",
    "# s2Data = []\n",
    "# if r.get_count() == 0:\n",
    "\n",
    "#     earningCallQa = []\n",
    "#     commonQuestions = [\n",
    "#         \"What are some of the current and looming threats to the business?\",\n",
    "#         \"What is the debt level or debt ratio of the company right now?\",\n",
    "#         \"How do you feel about the upcoming product launches or new products?\",\n",
    "#         \"How are you managing or investing in your human capital?\",\n",
    "#         \"How do you track the trends in your industry?\",\n",
    "#         \"Are there major slowdowns in the production of goods?\",\n",
    "#         \"How will you maintain or surpass this performance in the next few quarters?\",\n",
    "#         \"What will your market look like in five years as a result of using your product or service?\",\n",
    "#         \"How are you going to address the risks that will affect the long-term growth of the company?\",\n",
    "#         \"How is the performance this quarter going to affect the long-term goals of the company?\"\n",
    "#     ]\n",
    "\n",
    "#     for question in commonQuestions:\n",
    "#         answer = findAnswer('map_reduce', 3, question, earningVectorIndexName)\n",
    "#         if \"I don't know\" not in answer:\n",
    "#             earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "#     commonQuestions = [\n",
    "#         \"Provide key information about revenue for the quarter\",\n",
    "#         \"Provide key information about profits and losses (P&L) for the quarter\",\n",
    "#         \"Provide key information about industry trends for the quarter\",\n",
    "#         \"Provide key information about business trends discussed on the call\",\n",
    "#         \"Provide key information about risk discussed on the call\",\n",
    "#         \"Provide key information about AI discussed on the call\",\n",
    "#         \"Provide any information about mergers and acquisitions (M&A) discussed on the call.\",\n",
    "#         \"Provide key information about guidance discussed on the call\"\n",
    "#     ]\n",
    "\n",
    "#     for question in commonQuestions:\n",
    "#         answer = findAnswer('map_reduce', 3, question, earningVectorIndexName)\n",
    "#         if \"I don't know\" not in answer:\n",
    "#             earningCallQa.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "#     # With the data indexed, let's summarize the information\n",
    "#     # While we are using the standard prompt by langchain, you can modify the prompt to suit your needs\n",
    "#     # 1. Financial Results Summary: Please provide a summary of the financial results.\n",
    "#     # 2. Business Highlights: Please provide a summary of the business highlights.\n",
    "#     # 3. Future Outlook: Please provide a summary of the future outlook.\n",
    "#     # 4. Business Risks: Please provide a summary of the business risks.\n",
    "#     # 5. Management Positive Sentiment: Please provide a summary of the what management is confident about.\n",
    "#     # 6. Management Negative Sentiment: Please provide a summary of the what management is concerned about.\n",
    "#     # 7. Future Growth Strategies : Please generate a concise and comprehensive strategies summary that includes the information in  bulleted format.\n",
    "#     # 8. Risk Increase: Please provide a summary of the risks that have increased.\n",
    "#     # 9. Risk Decrease: Please provide a summary of the risks that have decreased.\n",
    "#     # 10. Opportunity Increase: Please provide a summary of the opportunities that have increased.\n",
    "#     # 11. Opportunity Decrease: Please provide a summary of the opportunities that have decreased.\n",
    "#     commonSummary = [\n",
    "#         \"Financial Results\",\n",
    "#         \"Business Highlights\",\n",
    "#         \"Future Outlook\",\n",
    "#         \"Business Risks\",\n",
    "#         \"Management Positive Sentiment\",\n",
    "#         \"Management Negative Sentiment\",\n",
    "#         \"Future Growth Strategies\"\n",
    "#     ]\n",
    "\n",
    "#     promptTemplate = \"\"\"You are an AI assistant tasked with summarizing financial information from earning call transcript. \n",
    "#             Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "#             Please generate a concise and comprehensive summary on the following topics. \n",
    "#             {summarize}\n",
    "#             Please remember to use clear language and maintain the integrity of the original information without missing any important details:\n",
    "#             {text}\n",
    "#             \"\"\"\n",
    "#     for summary in commonSummary:\n",
    "#         customPrompt = PromptTemplate(template=promptTemplate.replace('{summarize}', summary), input_variables=[\"text\"])\n",
    "#         chainType = \"map_reduce\"\n",
    "#         summaryChain = load_summarize_chain(llmChat, chain_type=chainType, return_intermediate_steps=False, \n",
    "#                                     map_prompt=customPrompt, combine_prompt=customPrompt)\n",
    "#         summaryOutput = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "#         outputAnswer = summaryOutput['output_text'].replace('Summary:', '')\n",
    "#         if \"I don't know\" not in answer and len(outputAnswer) > 0:\n",
    "#             earningCallQa.append({\"question\": summary, \"answer\": outputAnswer})\n",
    "\n",
    "#     s2Data.append({\n",
    "#                 'id' : str(uuid.uuid4()),\n",
    "#                 'symbol': symbol,\n",
    "#                 'cik': cik,\n",
    "#                 'step': step,\n",
    "#                 'description': 'Earning Call Q&A',\n",
    "#                 'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "#                 'pibData' : str(earningCallQa)\n",
    "#         })\n",
    "#     mergeDocs(SearchService, SearchKey, pibIndexName, s2Data)\n",
    "# else:\n",
    "#     print('Found existing data')\n",
    "#     for s in r:\n",
    "#         s2Data.append(\n",
    "#             {\n",
    "#                 'id' : s['id'],\n",
    "#                 'symbol': s['symbol'],\n",
    "#                 'cik': s['cik'],\n",
    "#                 'step': s['step'],\n",
    "#                 'description': s['description'],\n",
    "#                 'insertedDate': s['insertedDate'],\n",
    "#                 'pibData' : s['pibData']\n",
    "#             })\n",
    "        \n",
    "# print(s2Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case if we wanted to see summary of summary, run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the chaintype of MapReduce and Refine, we can also get insight into intermediate steps of the pipeline.\n",
    "# # This way you can inspect the results from map_reduce chain type, each top similar chunk summary\n",
    "# intermediateSteps = summary['intermediate_steps']\n",
    "# for step in intermediateSteps:\n",
    "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Paid Data - Press Releases - Get the Press Releases for last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizePressReleases(llm, docs):\n",
    "    promptTemplate = \"\"\"You are an AI assistant tasked with summarizing company's press releases and performing sentiments on those. \n",
    "                Your summary should accurately capture the key information in the press-releases while avoiding the omission of any domain-specific words. \n",
    "                Please generate a concise and comprehensive summary and sentiment with score with range of 0 to 10. \n",
    "                Your response should be in JSON object with following keys.  All JSON properties are required.\n",
    "                summary: \n",
    "                sentiment:\n",
    "                sentiment score: \n",
    "                {text}\n",
    "                \"\"\"\n",
    "    customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "    chainType = \"stuff\"\n",
    "    summaryChain = load_summarize_chain(llm, chain_type=chainType, prompt=customPrompt)\n",
    "    summary = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "    outputAnswer = summary['output_text']\n",
    "    return outputAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data\n",
      "[{'id': '198c468b-7362-4937-b74a-5fe98e952f68', 'symbol': 'NTRS', 'cik': '73124', 'step': '3', 'description': 'Press Releases', 'insertedDate': '2023-07-26', 'pibData': '[{\\'releaseDate\\': \\'2023-07-26 17:19:00\\', \\'title\\': \\'NORTHERN TRUST RAISES PRIME RATE\\', \\'summary\\': \\'Northern Trust has increased its prime rate from 8.25% to 8.50%, effective Thursday, July 27, 2023.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-07-19 07:24:00\\', \\'title\\': \\'NORTHERN TRUST CORPORATION REPORTS SECOND QUARTER 2023 FINANCIAL RESULTS\\', \\'summary\\': \"Northern Trust Corporation has released its second quarter 2023 financial results. The results can be found on the company\\'s website and on the SEC\\'s website. There will also be a webcast of the second quarter earnings conference call.\", \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.0}, {\\'releaseDate\\': \\'2023-07-18 17:55:00\\', \\'title\\': \\'NORTHERN TRUST DECLARES QUARTERLY DIVIDENDS ON COMMON AND PREFERRED STOCK\\', \\'summary\\': \\'Northern Trust Corporation has declared a quarterly cash dividend of $0.75 per share on its common stock and cash dividends of $2,300 per share of its Series D non-cumulative perpetual preferred stock.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-06-01 04:32:00\\', \\'title\\': \\'BRIGHTWELL REAPPOINTS NORTHERN TRUST FOR INVESTMENT OPERATIONS OUTSOURCING SERVICES\\', \\'summary\\': \\'Northern Trust has been reappointed by Brightwell as its provider of investment operations outsourcing services for the UK Defined Benefit Pension Scheme. Brightwell, formerly known as BT Pension Scheme Management, is the primary service provider to the BT Pension Scheme (BTPS), which is a DB pension scheme for employees, former employees, and dependents of BT Group PLC and some of its associated companies.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-17 10:15:00\\', \\'title\\': \"NORTHERN TRUST\\'S OUTSOURCED TRADING SUPPORTS BONDBLOXX\\'S GROWING FIXED INCOME ETF BUSINESS\", \\'summary\\': \"BondBloxx, a fixed income asset management company, has expanded the number of its funds that utilize Northern Trust\\'s integrated trading solutions.\", \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-09 10:00:00\\', \\'title\\': \\'NORTHERN TRUST APPOINTED BY ARTEMIS FOR MIDDLE OFFICE OUTSOURCING AND FUND SERVICING MANDATE\\', \\'summary\\': \\'Northern Trust has been appointed to provide whole office outsourcing solutions for Artemis, a leading UK-based asset manager with over Â£24.3 billion in assets under management. Northern Trust will be the single provider of asset servicing solutions for Artemis, which offers a range of funds investing globally.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-04 10:15:00\\', \\'title\\': \\'NORTHERN TRUST UNIVERSE DATA: DIMINISHING RECESSION CONCERNS BRING POSITIVE RESULTS IN THE FIRST QUARTER\\', \\'summary\\': \\'The median plan in the Northern Trust universe of institutional investors gained 4.1% in Q1 2023.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-05-03 17:48:00\\', \\'title\\': \\'NORTHERN TRUST RAISES PRIME RATE\\', \\'summary\\': \\'Northern Trust has increased its prime rate from 8.00% to 8.25%, effective Thursday, May 4, 2023.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-04-26 11:24:00\\', \\'title\\': \\'NORTHERN TRUST DECLARES QUARTERLY DIVIDENDS ON COMMON AND PREFERRED STOCK\\', \\'summary\\': \\'Northern Trust Corporation has declared a quarterly cash dividend of $0.75 per share on its common stock and cash dividends of $293.75 per share of its Series E non-cumulative perpetual preferred stock.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-04-25 07:19:00\\', \\'title\\': \\'NORTHERN TRUST CORPORATION REPORTS FIRST QUARTER 2023 FINANCIAL RESULTS\\', \\'summary\\': \"Northern Trust Corporation has released its first quarter 2023 financial results. The results can be found on the company\\'s website and on the SEC\\'s website. There will also be a webcast of the first quarter earnings conference call.\", \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.0}, {\\'releaseDate\\': \\'2023-04-03 04:00:00\\', \\'title\\': \\'NORTHERN TRUST LAUNCHES MARKET RISK MONITOR\\', \\'summary\\': \"Northern Trust has launched its new Market Risk Monitor solution, enhancing its suite of ex-ante risk analytics services. The solution provides institutional investor clients with a library of key risk indicators including stress tests, sensitivity shocks, and value-at-risk measures, all accessible through Northern Trust\\'s digital dashboard for investment analytics, RADARTM.\", \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-03-30 09:00:00\\', \\'title\\': \\'NORTHERN TRUST ENHANCES DIGITAL WORKFLOW EXPERIENCE FOR PRIVATE CAPITAL FUND MANAGERS\\', \\'summary\\': \\'Northern Trust is collaborating with Appian to enhance the net asset value (NAV) workflow communications between private capital fund managers and Northern Trust through digitizing events across the NAV production lifecycle.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-03-30 04:00:00\\', \\'title\\': \\'NORTHERN TRUST ENHANCES DIGITAL WORKFLOW EXPERIENCE FOR PRIVATE CAPITAL FUND MANAGERS\\', \\'summary\\': \\'Northern Trust is collaborating with Appian to enhance the net asset value (NAV) workflow communications between private capital fund managers and Northern Trust. The collaboration aims to provide private capital fund managers with a secure digital experience that offers enhanced efficiency, oversight, and data security across the NAV production lifecycle.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-03-29 03:00:00\\', \\'title\\': \\'NORTHERN TRUST APPOINTED CUSTODIAN FOR 2.3 BILLION EURO STICHTING PENSIOENFONDS OPENBARE BIBLIOTHEKEN\\', \\'summary\\': \\'Northern Trust has been appointed by Stichting Pensioenfonds Openbare Bibliotheken (POB) to provide global custody and compliance monitoring services. POB is a Dutch pension scheme dedicated to the library sector in the Netherlands with approximately 25,000 members and EUR2.3 billion in assets.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-03-22 17:26:00\\', \\'title\\': \\'NORTHERN TRUST RAISES PRIME RATE\\', \\'summary\\': \\'Northern Trust has increased its prime rate from 7.75% to 8.00%, effective Thursday, March 23, 2023.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-03-22 16:15:00\\', \\'title\\': \\'STEPHEN BOWMAN AND HIKMET ERSEK JOIN VOYA FINANCIAL BOARD OF DIRECTORS\\', \\'summary\\': \"Voya Financial, Inc. announced the election of Stephen \\'Biff\\' Bowman and Hikmet Ersek to the company\\'s board of directors. Bowman was previously the CFO of Northern Trust Corporation.\", \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-03-07 09:15:00\\', \\'title\\': \\'NORTHERN TRUST AND EDS ANNOUNCE NEW COLLABORATION WITH UK-BASED ASSET MANAGER REDWHEEL\\', \\'summary\\': \\'Northern Trust announces that Redwheel, a UK-based asset manager, is now using its data aggregation tool to enhance ESG integration across its investment business.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-02-28 17:15:00\\', \\'title\\': \\'NORTHERN TRUST RELEASES 2022 PHILANTHROPIC IMPACT REPORT\\', \\'summary\\': \\'Northern Trust has donated over $165 million to non-profit organizations in the past decade, including $19 million in 2022. The donations support initiatives related to food security, affordable housing, accessible healthcare, and quality education. Northern Trust employees have also contributed over 1 million hours of volunteer service.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 9.5}, {\\'releaseDate\\': \\'2023-02-22 04:18:00\\', \\'title\\': \\'NORTHERN TRUST TO OFFER INTEGRATION WITH SIMCORP AS PART OF ITS WHOLE OFFICEâ¢ STRATEGY\\', \\'summary\\': \\'Northern Trust has reached an agreement with SimCorp to enable integration for efficient data exchange for clients using the SimCorp Dimension platform.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-02-09 07:45:00\\', \\'title\\': \\'NORTHERN TRUST ANNOUNCES NEW PRESIDENT OF ASSET MANAGEMENT BUSINESS\\', \\'summary\\': \"Northern Trust has announced that Daniel Gamba will be the new President of Asset Management, effective April 3. Gamba will report to CEO Michael O\\'Grady and join Northern Trust\\'s management group. He joins from BlackRock, Inc.\", \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-02-02 04:41:00\\', \\'title\\': \\'NORTHERN TRUST ASSET MANAGEMENT LAUNCHES NATURAL CAPITAL PARIS-ALIGNED STRATEGY\\', \\'summary\\': \\'Northern Trust Asset Management (NTAM) has launched the World Natural Capital Paris-Aligned Index Strategy, expanding its sustainable index investment solutions.\\', \\'sentiment\\': \\'Positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-02-01 18:11:00\\', \\'title\\': \\'NORTHERN TRUST RAISES PRIME RATE\\', \\'summary\\': \\'Northern Trust increases prime rate from 7.50% to 7.75%\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-01-26 11:15:00\\', \\'title\\': \\'NORTHERN TRUST PENSION UNIVERSE DATA: CANADIAN PENSION PLANS RETURNED POSITIVE RESULTS FOR Q4 2022 AS GLOBAL EQUITIES GAINED MOMENTUM\\', \\'summary\\': \\'Canadian pension plan investment returns advanced during the quarter, but experienced a double-digit decline for the year due to market volatility, according to Northern Trust Canada Universe.\\', \\'sentiment\\': \\'Negative\\', \\'sentimentScore\\': 3.5}, {\\'releaseDate\\': \\'2023-01-24 10:00:00\\', \\'title\\': \\'NORTHERN TRUST ASSET MANAGEMENT NAMES CLIENT PORTFOLIO MANAGER FOR MUNI TEAM\\', \\'summary\\': \\'Northern Trust Asset Management (NTAM) has hired John Ceffalio as Head of Municipal Client Portfolio Management, a newly created position within its Global Fixed Income Group.\\', \\'sentiment\\': \\'positive\\', \\'sentimentScore\\': 8.5}, {\\'releaseDate\\': \\'2023-01-19 07:10:00\\', \\'title\\': \\'NORTHERN TRUST CORPORATION REPORTS FOURTH QUARTER 2022 FINANCIAL RESULTS\\', \\'summary\\': \\'Northern Trust Corporation has released its fourth quarter 2022 financial results.\\', \\'sentiment\\': \\'Neutral\\', \\'sentimentScore\\': 5.0}]'}]\n"
     ]
    }
   ],
   "source": [
    "# For now we are calling API to get data, but otherwise we need to ensure the data is not persisted in our \n",
    "# index repository before calling again, if it is persisted then we need to delete it first\n",
    "step = \"3\"\n",
    "s3Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "if r.get_count() == 0:\n",
    "    counter = 0\n",
    "    pressReleasesList = []\n",
    "    pressReleaseIndexName = 'pressreleases'\n",
    "    # Create the index if it does not exist\n",
    "    createPressReleaseIndex(SearchService, SearchKey, pressReleaseIndexName)\n",
    "    print(f\"Processing ticker : {symbol}\")\n",
    "    pr = pressReleases(apikey=apikey, symbol=symbol, limit=25)\n",
    "    for pressRelease in pr:\n",
    "        symbol = pressRelease['symbol']\n",
    "        releaseDate = pressRelease['date']\n",
    "        title = pressRelease['title']\n",
    "        content = pressRelease['text']\n",
    "        todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "        id = f\"{symbol}-{counter}\"\n",
    "        pressReleasesList.append({\n",
    "            \"id\": id,\n",
    "            \"symbol\": symbol,\n",
    "            \"releaseDate\": releaseDate,\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "        })\n",
    "        counter = counter + 1\n",
    "\n",
    "    mergeDocs(SearchService, SearchKey, pressReleaseIndexName, pressReleasesList)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "    rawPressReleasesDoc = [Document(page_content=t['content']) for t in pressReleasesList[:25]]\n",
    "    pressReleasesDocs = splitter.split_documents(rawPressReleasesDoc)\n",
    "    print(\"Number of documents chunks generated from Press releases : \", len(pressReleasesDocs))\n",
    "\n",
    "    pressReleasesPib = []\n",
    "    last25PressReleases = pressReleasesList[:25]\n",
    "    i = 0\n",
    "    for pDocs in pressReleasesDocs:\n",
    "        try:\n",
    "            outputAnswer = summarizePressReleases(llmChat, [pDocs])\n",
    "            jsonStep = json.loads(outputAnswer)\n",
    "            pressReleasesPib.append({\n",
    "                    \"releaseDate\": last25PressReleases[i]['releaseDate'],\n",
    "                    \"title\": last25PressReleases[i]['title'],\n",
    "                    \"summary\": jsonStep['summary'],\n",
    "                    \"sentiment\": jsonStep['sentiment'],\n",
    "                    \"sentimentScore\": jsonStep['sentiment score']\n",
    "            })\n",
    "            i = i + 1\n",
    "        except Exception as e:\n",
    "            i = i + 1\n",
    "            continue\n",
    "    \n",
    "    s3Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Press Releases',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(pressReleasesPib)\n",
    "        })\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s3Data)\n",
    "else:\n",
    "    print('Found existing data')\n",
    "    for s in r:\n",
    "        s3Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })\n",
    "\n",
    "print(s3Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Paid Data - Get Stock News - Limit it to cover for current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For now we are calling API to get data, but otherwise we need to ensure the data is not persisted in our \n",
    "# # index repository before calling again, if it is persisted then we need to delete it first\n",
    "# counter = 0\n",
    "# stockNewsList = []\n",
    "# stockNewsIndexName = 'stocknews'\n",
    "# # Create the index if it does not exist\n",
    "# createStockNewsIndex(SearchService, SearchKey, stockNewsIndexName)\n",
    "# print(f\"Processing ticker : {symbol}\")\n",
    "# sn = stockNews(apikey=apikey, tickers=symbol, limit=5000)\n",
    "# for news in sn:\n",
    "#     symbol = news['symbol']\n",
    "#     publishedDate = news['publishedDate']\n",
    "#     title = news['title']\n",
    "#     image = news['image']\n",
    "#     site = news['site']\n",
    "#     content = news['text']\n",
    "#     url = news['url']\n",
    "#     todayYmd = today.strftime(\"%Y-%m-%d\")\n",
    "#     id = f\"{symbol}-{todayYmd}-{counter}\"\n",
    "#     stockNewsList.append({\n",
    "#         \"id\": id,\n",
    "#         \"symbol\": symbol,\n",
    "#         \"publishedDate\": publishedDate,\n",
    "#         \"title\": title,\n",
    "#         \"image\": image,\n",
    "#         \"site\": site,\n",
    "#         \"content\": content,\n",
    "#         \"url\": url,\n",
    "#     })\n",
    "#     counter = counter + 1\n",
    "# mergeDocs(SearchService, SearchKey, stockNewsIndexName, stockNewsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group our news by Date and summarize the content and sentimet per day\n",
    "# stocksDf = pd.DataFrame.from_dict(pd.json_normalize(stockNewsList))\n",
    "# stocksDf['publishedDate'] = pd.to_datetime(stocksDf['publishedDate']).dt.date\n",
    "# stocksNewsDailyDf = stocksDf.sort_values('publishedDate').groupby('publishedDate')['content'].apply('\\n'.join).reset_index()\n",
    "# splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "# rawNewsDocs = [Document(page_content=row['content']) for index, row in stocksNewsDailyDf.tail(10).iterrows()]\n",
    "# newsDocs = splitter.split_documents(rawNewsDocs)\n",
    "# print(\"Number of documents chunks generated from Press releases : \", len(newsDocs))\n",
    "\n",
    "# # With the data indexed, let's summarize the information\n",
    "# promptTemplate = \"\"\"You are an AI assistant tasked with summarizing news related to company and performing sentiments on those. \n",
    "#         Your summary should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "#         Please generate a concise and comprehensive summary and sentiment with score with range of 0 to 10. Your response should be in JSON format with following keys.\n",
    "#         summary: \n",
    "#         sentiment:\n",
    "#         sentiment score:\n",
    "#         Please remember to use clear language and maintain the integrity of the original information without missing any important details.\n",
    "#         {text}\n",
    "#         \"\"\"\n",
    "# customPrompt = PromptTemplate(template=promptTemplate, input_variables=[\"text\"])\n",
    "# chainType = \"map_reduce\"\n",
    "# summaryChain = load_summarize_chain(llm, chain_type=chainType, return_intermediate_steps=True, \n",
    "#                                     map_prompt=customPrompt, combine_prompt=customPrompt)\n",
    "# summary = summaryChain({\"input_documents\": newsDocs}, return_only_outputs=True)\n",
    "# outputAnswer = summary['output_text']\n",
    "# print(outputAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For the chaintype of MapReduce and Refine, we can also get insight into intermediate steps of the pipeline.\n",
    "# # This way you can inspect the results from map_reduce chain type, each top similar chunk summary\n",
    "# intermediateSteps = summary['intermediate_steps']\n",
    "# for step in intermediateSteps:\n",
    "#         display(HTML(\"<b>Chunk Summary:</b> \" + step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Public Data - Get the SEC Filings - Limit it to cover for last 3 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "filingType = \"10-K\"\n",
    "secFilingsList = secFilings(apikey=apikey, symbol=symbol, filing_type=filingType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index latestsecfilings already exists\n",
      "Latest SEC Filings for CIK :  73124  and Symbol :  NTRS  already processed\n"
     ]
    }
   ],
   "source": [
    "latestFilingDateTime = datetime.strptime(secFilingsList[0]['fillingDate'], '%Y-%m-%d %H:%M:%S')\n",
    "latestFilingDate = latestFilingDateTime.strftime(\"%Y-%m-%d\")\n",
    "filingYear = latestFilingDateTime.strftime(\"%Y\")\n",
    "filingMonth = int(latestFilingDateTime.strftime(\"%m\"))\n",
    "\n",
    "if filingMonth > 0 & filingMonth <= 3:\n",
    "    filingQuarter = 1\n",
    "elif filingMonth > 3 & filingMonth <= 6:\n",
    "    filingQuarter = 2\n",
    "elif filingMonth > 6 & filingMonth <= 9:\n",
    "    filingQuarter = 3\n",
    "else:\n",
    "    filingQuarter = 4\n",
    "\n",
    "\n",
    "secFilingIndexName = 'secdata'\n",
    "secFilingList = []\n",
    "dt = pd.to_datetime(datetime.now(), format='%Y/%m/%d')\n",
    "dt1 = pd.to_datetime(latestFilingDate, format='%Y/%m/%d')\n",
    "totalDays = (dt-dt1).days\n",
    "if totalDays < 31:\n",
    "    skipIndicies = False\n",
    "else:\n",
    "    skipIndicies = True\n",
    "emptyBody = {\n",
    "        \"values\": [\n",
    "            {\n",
    "                \"recordId\": 0,\n",
    "                \"data\": {\n",
    "                    \"text\": \"\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "\n",
    "secExtractBody = {\n",
    "    \"values\": [\n",
    "        {\n",
    "            \"recordId\": 0,\n",
    "            \"data\": {\n",
    "                \"text\": {\n",
    "                    \"edgar_crawler\": {\n",
    "                        \"start_year\": int(filingYear),\n",
    "                        \"end_year\": int(filingYear),\n",
    "                        \"quarters\": [filingQuarter],\n",
    "                        \"filing_types\": [\n",
    "                            \"10-K\"\n",
    "                        ],\n",
    "                        \"cik_tickers\": [cik],\n",
    "                        \"user_agent\": \"Your name (your email)\",\n",
    "                        \"raw_filings_folder\": \"RAW_FILINGS\",\n",
    "                        \"indices_folder\": \"INDICES\",\n",
    "                        \"filings_metadata_file\": \"FILINGS_METADATA.csv\",\n",
    "                        \"skip_present_indices\": skipIndicies,\n",
    "                    },\n",
    "                    \"extract_items\": {\n",
    "                        \"raw_filings_folder\": \"RAW_FILINGS\",\n",
    "                        \"extracted_filings_folder\": \"EXTRACTED_FILINGS\",\n",
    "                        \"filings_metadata_file\": \"FILINGS_METADATA.csv\",\n",
    "                        \"items_to_extract\": [\"1\",\"1A\",\"1B\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"7A\",\"8\",\"9\",\"9A\",\"9B\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\"],\n",
    "                        \"remove_tables\": False,\n",
    "                        \"skip_extracted_filings\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Check if we have already processed the latest filing, if yes then skip\n",
    "createSecFilingIndex(SearchService, SearchKey, secFilingIndexName)\n",
    "r = findSecFiling(SearchService, SearchKey, secFilingIndexName, cik, filingType, latestFilingDate, returnFields=['id', 'cik', 'company', 'filingType', 'filingDate',\n",
    "                                                                                                                 'periodOfReport', 'sic', 'stateOfInc', 'fiscalYearEnd',\n",
    "                                                                                                                 'filingHtmlIndex', 'htmFilingLink', 'completeTextFilingLink',\n",
    "                                                                                                                 'item1', 'item1A', 'item1B', 'item2', 'item3', 'item4', 'item5',\n",
    "                                                                                                                 'item6', 'item7', 'item7A', 'item8', 'item9', 'item9A', 'item9B',\n",
    "                                                                                                                 'item10', 'item11', 'item12', 'item13', 'item14', 'item15',\n",
    "                                                                                                                 'sourcefile'])\n",
    "if r.get_count() == 0:\n",
    "    # Call Azure Function to perform Web-scraping and store the JSON in our blob\n",
    "    secExtract = requests.post(SecExtractionUrl, json = secExtractBody)\n",
    "    # Once the JSON is created, call the function to process the JSON and store the data in our index\n",
    "    docPersistUrl = SecDocPersistUrl + \"&indexType=cogsearchvs&indexName=\" + secFilingIndexName + \"&embeddingModelType=\" + embeddingModelType\n",
    "    secPersist = requests.post(docPersistUrl, json = emptyBody)\n",
    "    r = findSecFiling(SearchService, SearchKey, secFilingIndexName, cik, filingType, latestFilingDate, returnFields=['id', 'cik', 'company', 'filingType', 'filingDate',\n",
    "                                                                                                                 'periodOfReport', 'sic', 'stateOfInc', 'fiscalYearEnd',\n",
    "                                                                                                                 'filingHtmlIndex', 'htmFilingLink', 'completeTextFilingLink',\n",
    "                                                                                                                 'item1', 'item1A', 'item1B', 'item2', 'item3', 'item4', 'item5',\n",
    "                                                                                                                 'item6', 'item7', 'item7A', 'item8', 'item9', 'item9A', 'item9B',\n",
    "                                                                                                                 'item10', 'item11', 'item12', 'item13', 'item14', 'item15',\n",
    "                                                                                                                 'sourcefile'])\n",
    "\n",
    "lastSecData = ''\n",
    "# Retrieve the latest filing from our index\n",
    "for filing in r:\n",
    "    lastSecData = filing['item1'] + '\\n' + filing['item1A'] + '\\n' + filing['item1B'] + '\\n' + filing['item2'] + '\\n' + filing['item3'] + '\\n' + filing['item4'] + '\\n' + \\\n",
    "                filing['item5'] + '\\n' + filing['item6'] + '\\n' + filing['item7'] + '\\n' + filing['item7A'] + '\\n' + filing['item8'] + '\\n' + \\\n",
    "                filing['item9'] + '\\n' + filing['item9A'] + '\\n' + filing['item9B'] + '\\n' + filing['item10'] + '\\n' + filing['item11'] + '\\n' + filing['item12'] + '\\n' + \\\n",
    "                filing['item13'] + '\\n' + filing['item14'] + '\\n' + filing['item15']\n",
    "\n",
    "    secFilingList.append({\n",
    "        \"id\": filing['id'],\n",
    "        \"cik\": filing['cik'],\n",
    "        \"company\": filing['company'],\n",
    "        \"filingType\": filing['filingType'],\n",
    "        \"filingDate\": filing['filingDate'],\n",
    "        \"periodOfReport\": filing['periodOfReport'],\n",
    "        \"sic\": filing['sic'],\n",
    "        \"stateOfInc\": filing['stateOfInc'],\n",
    "        \"fiscalYearEnd\": filing['fiscalYearEnd'],\n",
    "        \"filingHtmlIndex\": filing['filingHtmlIndex'],\n",
    "        \"completeTextFilingLink\": filing['completeTextFilingLink'],\n",
    "        \"item1\": filing['item1'],\n",
    "        \"item1A\": filing['item1A'],\n",
    "        \"item1B\": filing['item1B'],\n",
    "        \"item2\": filing['item2'],\n",
    "        \"item3\": filing['item3'],\n",
    "        \"item4\": filing['item4'],\n",
    "        \"item5\": filing['item5'],\n",
    "        \"item6\": filing['item6'],\n",
    "        \"item7\": filing['item7'],\n",
    "        \"item7A\": filing['item7A'],\n",
    "        \"item8\": filing['item8'],\n",
    "        \"item9\": filing['item9'],\n",
    "        \"item9A\": filing['item9A'],\n",
    "        \"item9B\": filing['item9B'],\n",
    "        \"item10\": filing['item10'],\n",
    "        \"item11\": filing['item11'],\n",
    "        \"item12\": filing['item12'],\n",
    "        \"item13\": filing['item13'],\n",
    "        \"item14\": filing['item14'],\n",
    "        \"item15\": filing['item15'],\n",
    "        \"sourcefile\": filing['sourcefile']\n",
    "    })\n",
    "\n",
    "# Check if we have already processed the latest filing, if yes then skip\n",
    "secFilingsVectorIndexName = 'latestsecfilings'\n",
    "createSecFilingsVectorIndex(SearchService, SearchKey, secFilingsVectorIndexName)\n",
    "r = findLatestSecFilings(SearchService, SearchKey, secFilingsVectorIndexName, cik, symbol, latestFilingDate, filingType, returnFields=['id', 'cik', 'symbol', 'latestFilingDate', 'filingType',\n",
    "                                                                                                                 'content'])\n",
    "if r.get_count() == 0:\n",
    "    print(\"Processing latest SEC Filings for CIK : \", cik, \" and Symbol : \", symbol)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=1000)\n",
    "    rawDocs = splitter.create_documents([lastSecData])\n",
    "    docs = splitter.split_documents(rawDocs)\n",
    "    print(\"Number of documents chunks generated from Last SEC Filings : \", len(docs))\n",
    "\n",
    "    # Store the last index of the earning call transcript in vector Index\n",
    "    indexSecFilingsSections(OpenAiService, OpenAiKey, OpenAiVersion, OpenAiApiKey, SearchService, SearchKey,\n",
    "                         embeddingModelType, OpenAiEmbedding, secFilingsVectorIndexName, docs, cik,\n",
    "                         symbol, latestFilingDate, filingType)\n",
    "else:\n",
    "    print(\"Latest SEC Filings for CIK : \", cik, \" and Symbol : \", symbol, \" already processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item8 = secFilingList[0]['item8']\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=0)\n",
    "rawItemDocs8 = [Document(page_content=item8, metadata={'source': ''})]\n",
    "itemDocs8 = splitter.split_documents(rawItemDocs8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItem8Answer(llm, docs, question, chainType):\n",
    "    template = \"\"\"\n",
    "            You are an AI assistant tasked with answering questions from financial statements like income statement, cashflow and balance sheets. \n",
    "            The data that you are presented with is in table.\n",
    "            Your answer should accurately capture the key information in the document while avoiding the omission of any domain-specific words. \n",
    "            Please generate a concise and comprehensive information that includes details such as reporting year and amount in millions.\n",
    "            Ensure that it is easy to understand for business professionals and provides an accurate representation of the financial statement history. \n",
    "            \n",
    "            Please remember to use clear language and maintain the integrity of the original information without missing any important details\n",
    "\n",
    "            QUESTION: {question}\n",
    "            =========\n",
    "            {summaries}\n",
    "            =========\n",
    "            \"\"\"\n",
    "    qaPrompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "    qaChain = load_qa_with_sources_chain(llm, chain_type=chainType, combine_prompt=qaPrompt)\n",
    "    answer = qaChain({\"input_documents\": docs, \"question\": question})\n",
    "    outputAnswer = answer['output_text']\n",
    "    return outputAnswer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reported revenue for 2021 is not provided in the given portion of the document.\n",
      "SOURCES:\n"
     ]
    }
   ],
   "source": [
    "print(getItem8Answer(llmChat, itemDocs8, \"What was the reported revenue for 2021?\", \"map_reduce\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSummaries(docs):\n",
    "    chainType = \"map_reduce\"\n",
    "    summaryChain = load_summarize_chain(llm, chain_type=chainType)\n",
    "    summary = summaryChain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 data already exists in the index\n"
     ]
    }
   ],
   "source": [
    "step = \"4\"\n",
    "s4Data = []\n",
    "\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "if r.get_count() == 0:\n",
    "        secFilingsPib = []\n",
    "\n",
    "        # For different section of extracted data, process summarization and generate common answers to questions\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=8000, chunk_overlap=0)\n",
    "\n",
    "        # Item 1 - Describes the business of the company\n",
    "        rawItemDocs1 = [Document(page_content=secFilingList[0]['item1'])]\n",
    "        itemDocs1 = splitter.split_documents(rawItemDocs1)\n",
    "        print(\"Number of documents chunks generated from Item1 : \", len(itemDocs1))\n",
    "        summary1 = generateSummaries(itemDocs1)\n",
    "        outputAnswer1 = summary1['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item1\",\n",
    "                        \"summaryType\": \"Business Description\",\n",
    "                        \"summary\": outputAnswer1\n",
    "                })\n",
    "\n",
    "        # Item 1A - Risk Factors\n",
    "        rawItemDocs2 = [Document(page_content=secFilingList[0]['item1A'])]\n",
    "        itemDocs2 = splitter.split_documents(rawItemDocs2)\n",
    "        print(\"Number of documents chunks generated from Item1A : \", len(itemDocs2))\n",
    "        summary2 = generateSummaries(itemDocs2)\n",
    "        outputAnswer2 = summary2['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item1A\",\n",
    "                        \"summaryType\": \"Risk Factors\",\n",
    "                        \"summary\": outputAnswer2\n",
    "                })\n",
    "\n",
    "        rawItemDocs2 = [Document(page_content=secFilingList[0]['item3'])]\n",
    "        itemDocs2 = splitter.split_documents(rawItemDocs2)\n",
    "        print(\"Number of documents chunks generated from Item3 : \", len(itemDocs2))\n",
    "        summary2 = generateSummaries(itemDocs2)\n",
    "        outputAnswer2 = summary2['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item3\",\n",
    "                        \"summaryType\": \"Legal Proceedings\",\n",
    "                        \"summary\": outputAnswer2\n",
    "                })\n",
    "\n",
    "        # Item 6 - Consolidated Financial Data\n",
    "        rawItemDocs3 = [Document(page_content=secFilingList[0]['item5'])]\n",
    "        itemDocs3 = splitter.split_documents(rawItemDocs3)\n",
    "        print(\"Number of documents chunks generated from Item5 : \", len(itemDocs3))\n",
    "        summary3 = generateSummaries(itemDocs3)\n",
    "        outputAnswer3 = summary3['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item5\",\n",
    "                        \"summaryType\": \"Market\",\n",
    "                        \"summary\": outputAnswer3\n",
    "                })\n",
    "\n",
    "        # Item 7 - Management's Discussion and Analysis of Financial Condition and Results of Operations\n",
    "        rawItemDocs4 = [Document(page_content=secFilingList[0]['item7'])]\n",
    "        itemDocs4 = splitter.split_documents(rawItemDocs4)\n",
    "        print(\"Number of documents chunks generated from Item7 : \", len(itemDocs4))\n",
    "        summary4 = generateSummaries(itemDocs4)\n",
    "        outputAnswer4 = summary4['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item7\",\n",
    "                        \"summaryType\": \"Management Discussion\",\n",
    "                        \"summary\": outputAnswer4\n",
    "                })\n",
    "\n",
    "        # Item 7a - Market risk disclosures\n",
    "        rawItemDocs5 = [Document(page_content=secFilingList[0]['item7A'])]\n",
    "        itemDocs5= splitter.split_documents(rawItemDocs5)\n",
    "        print(\"Number of documents chunks generated from Item7A : \", len(itemDocs5))\n",
    "        summary5 = generateSummaries(itemDocs5)\n",
    "        outputAnswer5 = summary5['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item7A\",\n",
    "                        \"summaryType\": \"Risk Disclosures\",\n",
    "                        \"summary\": outputAnswer5\n",
    "                })\n",
    "\n",
    "        # Item 9 - Disagreements with accountants and changes in accounting\n",
    "        section9 = secFilingList[0]['item9'] + \"\\n \" + secFilingList[0]['item9A'] + \"\\n \" + secFilingList[0]['item9B']\n",
    "        rawItemDocs6 = [Document(page_content=section9)]\n",
    "        itemDocs6 = splitter.split_documents(rawItemDocs6)\n",
    "        print(\"Number of documents chunks generated from Item9 : \", len(itemDocs6))\n",
    "        summary6 = generateSummaries(itemDocs6)\n",
    "        outputAnswer6 = summary6['output_text']\n",
    "        secFilingsPib.append({\n",
    "                        \"section\": \"item9\",\n",
    "                        \"summaryType\": \"Accounting Disclosures\",\n",
    "                        \"summary\": outputAnswer6\n",
    "                })\n",
    "        \n",
    "        s4Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'SEC Filings',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(secFilingsPib)\n",
    "        })\n",
    "        mergeDocs(SearchService, SearchKey, pibIndexName, s4Data)\n",
    "else:\n",
    "        print(\"Step 4 data already exists in the index\")\n",
    "        for item in r:\n",
    "                s4Data.append({\n",
    "                        'id' : item['id'],\n",
    "                        'symbol': item['symbol'],\n",
    "                        'cik': item['cik'],\n",
    "                        'step': item['step'],\n",
    "                        'description': item['description'],\n",
    "                        'insertedDate': item['insertedDate'],\n",
    "                        'pibData' : item['pibData']\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Private Data - Equity Research Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.search.documents import SearchClient\n",
    "# from azure.core.credentials import AzureKeyCredential\n",
    "# step = \"5\"\n",
    "# searchClient = SearchClient(endpoint=f\"https://{SearchService}.search.windows.net\",\n",
    "#         index_name=pibIndexName,\n",
    "#         credential=AzureKeyCredential(SearchKey))\n",
    "# r = searchClient.search(  \n",
    "#     search_text=\"\",\n",
    "#     filter=\"cik eq '\" + cik + \"' and step eq '\" + step + \"'\",\n",
    "#     select=[\"id\"],\n",
    "#     semantic_configuration_name=\"semanticConfig\",\n",
    "#     include_total_count=True\n",
    "# )\n",
    "# if r.get_count() > 0:\n",
    "#     for doc in r:\n",
    "#         searchClient.delete_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = \"5\"\n",
    "s5Data = []\n",
    "r = findPibData(SearchService, SearchKey, pibIndexName, cik, step, returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "                                                                   'pibData'])\n",
    "\n",
    "if r.get_count() == 0:\n",
    "    companyRating = rating(apikey=apikey, symbol=symbol)\n",
    "    fScore = financialScore(apikey=apikey, symbol=symbol)\n",
    "    esgScores = esgScore(apikey=apikey, symbol=symbol)\n",
    "    esgRating = esgRatings(apikey=apikey, symbol=symbol)\n",
    "    ugConsensus = upgradeDowngrades(apikey=apikey, symbol=symbol)\n",
    "    priceConsensus = priceTarget(apikey=apikey, symbol=symbol)\n",
    "    #ratingsDf = pd.DataFrame.from_dict(pd.json_normalize(companyRating))\n",
    "    researchReport = []\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Overall Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingRecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"DCF Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsDCFRecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"ROE Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsROERecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"ROA Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsROARecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"PB Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsPBRecommendation']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"PE Recommendation\",\n",
    "            \"value\": companyRating[0]['ratingDetailsPERecommendation']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for companyRating')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Altman ZScore\",\n",
    "            \"value\": fScore[0]['altmanZScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Piotroski Score\",\n",
    "            \"value\": fScore[0]['piotroskiScore']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for fScore')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Environmental Score\",\n",
    "            \"value\": esgScores[0]['environmentalScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Social Score\",\n",
    "            \"value\": esgScores[0]['socialScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Governance Score\",\n",
    "            \"value\": esgScores[0]['governanceScore']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"ESG Score\",\n",
    "            \"value\": esgScores[0]['ESGScore']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for esgScores')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"ESG RIsk Rating\",\n",
    "            \"value\": esgRating[0]['ESGRiskRating']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for esgRating')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Buy\",\n",
    "            \"value\": ugConsensus[0]['buy']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Sell\",\n",
    "            \"value\": ugConsensus[0]['sell']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Strong Buy\",\n",
    "            \"value\": ugConsensus[0]['strongBuy']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Strong Sell\",\n",
    "            \"value\": ugConsensus[0]['strongSell']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus Hold\",\n",
    "            \"value\": ugConsensus[0]['hold']\n",
    "        })\n",
    "        researchReport.append({\n",
    "            \"key\": \"Analyst Consensus\",\n",
    "            \"value\": ugConsensus[0]['consensus']\n",
    "        })\n",
    "    except:\n",
    "        logging.info('No data found for ugConsensus')\n",
    "        pass\n",
    "    # researchReport.append({\n",
    "    #     \"key\": \"Price Target Consensus\",\n",
    "    #     \"value\": priceConsensus[0]['targetConsensus']\n",
    "    # })\n",
    "    # researchReport.append({\n",
    "    #     \"key\": \"Price Target Median\",\n",
    "    #     \"value\": priceConsensus[0]['targetMedian']\n",
    "    # })\n",
    "  \n",
    "    s5Data.append({\n",
    "                'id' : str(uuid.uuid4()),\n",
    "                'symbol': symbol,\n",
    "                'cik': cik,\n",
    "                'step': step,\n",
    "                'description': 'Research Report',\n",
    "                'insertedDate': today.strftime(\"%Y-%m-%d\"),\n",
    "                'pibData' : str(researchReport)\n",
    "        })\n",
    "    mergeDocs(SearchService, SearchKey, pibIndexName, s5Data)\n",
    "else:\n",
    "    for s in r:\n",
    "        s5Data.append(\n",
    "            {\n",
    "                'id' : s['id'],\n",
    "                'symbol': s['symbol'],\n",
    "                'cik': s['cik'],\n",
    "                'step': s['step'],\n",
    "                'description': s['description'],\n",
    "                'insertedDate': s['insertedDate'],\n",
    "                'pibData' : s['pibData']\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Paid Data - Investor Presentations - Financial Reports (Balance Sheet, Income Statement and Cash Flow) for last 3 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2022-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2023-02-28', 'acceptedDate': '2023-02-28 16:20:50', 'calendarYear': '2022', 'period': 'FY', 'revenue': 6761200000, 'costOfRevenue': 0, 'grossProfit': 6761200000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2685400000, 'sellingAndMarketingExpenses': 76700000, 'sellingGeneralAndAdministrativeExpenses': 2685400000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 2877700000, 'interestExpense': 990500000, 'depreciationAndAmortization': 553600000, 'ebitda': 2816000000, 'ebitdaratio': 0.4164941135, 'operatingIncome': 2262400000, 'operatingIncomeRatio': 0.3346151571, 'totalOtherIncomeExpensesNet': -496100000, 'incomeBeforeTax': 1766300000, 'incomeBeforeTaxRatio': 0.2612406082, 'incomeTaxExpense': 430300000, 'netIncome': 1336000000, 'netIncomeRatio': 0.1975980595, 'eps': 6.16, 'epsdiluted': 6.14, 'weightedAverageShsOut': 208309331, 'weightedAverageShsOutDil': 208867264, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312423000049/0000073124-23-000049-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312423000049/ntrs-20221231.htm'}, {'date': '2021-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2022-02-28', 'acceptedDate': '2022-02-28 16:35:35', 'calendarYear': '2021', 'period': 'FY', 'revenue': 6464500000, 'costOfRevenue': 0, 'grossProfit': 6464500000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2442400000, 'sellingAndMarketingExpenses': 65500000, 'sellingGeneralAndAdministrativeExpenses': 2442400000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 1406500000, 'interestExpense': 23800000, 'depreciationAndAmortization': 515600000, 'ebitda': 2525700000, 'ebitdaratio': 0.3907030706, 'operatingIncome': 2010100000, 'operatingIncomeRatio': 0.3109443886, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 2010100000, 'incomeBeforeTaxRatio': 0.3109443886, 'incomeTaxExpense': 464800000, 'netIncome': 1545300000, 'netIncomeRatio': 0.2390440096, 'eps': 7.16, 'epsdiluted': 7.14, 'weightedAverageShsOut': 208076000, 'weightedAverageShsOutDil': 208899000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312422000071/0000073124-22-000071-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312422000071/ntrs-20211231.htm'}, {'date': '2020-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2021-02-23', 'acceptedDate': '2021-02-23 16:51:30', 'calendarYear': '2020', 'period': 'FY', 'revenue': 6100800000, 'costOfRevenue': 0, 'grossProfit': 6100800000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2334800000, 'sellingAndMarketingExpenses': 59200000, 'sellingGeneralAndAdministrativeExpenses': 2334800000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 1643500000, 'interestExpense': 200300000, 'depreciationAndAmortization': 500300000, 'ebitda': 2127900000, 'ebitdaratio': 0.3487903226, 'operatingIncome': 1627600000, 'operatingIncomeRatio': 0.266784684, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1627600000, 'incomeBeforeTaxRatio': 0.266784684, 'incomeTaxExpense': 418300000, 'netIncome': 1209300000, 'netIncomeRatio': 0.1982199056, 'eps': 5.48, 'epsdiluted': 5.46, 'weightedAverageShsOut': 208319412, 'weightedAverageShsOutDil': 209007986, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312421000071/0000073124-21-000071-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312421000071/ntrs-20201231.htm'}, {'date': '2019-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2020-02-25', 'acceptedDate': '2020-02-25 17:06:15', 'calendarYear': '2019', 'period': 'FY', 'revenue': 6073100000, 'costOfRevenue': 0, 'grossProfit': 6073100000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2214200000, 'sellingAndMarketingExpenses': 104200000, 'sellingGeneralAndAdministrativeExpenses': 2214200000, 'otherExpenses': 0, 'operatingExpenses': 0, 'costAndExpenses': 0, 'interestIncome': 2499900000, 'interestExpense': 822000000, 'depreciationAndAmortization': 458900000, 'ebitda': 2403000000, 'ebitdaratio': 0.3956793071, 'operatingIncome': 1944100000, 'operatingIncomeRatio': 0.3201165797, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1944100000, 'incomeBeforeTaxRatio': 0.3201165797, 'incomeTaxExpense': 451900000, 'netIncome': 1492200000, 'netIncomeRatio': 0.2457064761, 'eps': 6.66, 'epsdiluted': 6.63, 'weightedAverageShsOut': 214525547, 'weightedAverageShsOutDil': 215601149, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312420000101/0000073124-20-000101-index.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312420000101/a201910-k.htm'}, {'date': '2018-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2019-02-26', 'acceptedDate': '2019-02-26 16:37:47', 'calendarYear': '2018', 'period': 'FY', 'revenue': 5220800000, 'costOfRevenue': 0, 'grossProfit': 5220800000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2224600000, 'sellingAndMarketingExpenses': 98300000, 'sellingGeneralAndAdministrativeExpenses': 2322900000, 'otherExpenses': 2378100000, 'operatingExpenses': 4701000000, 'costAndExpenses': 0, 'interestIncome': 2321400000, 'interestExpense': 698700000, 'depreciationAndAmortization': 460900000, 'ebitda': 3117400000, 'ebitdaratio': 0.5971115537848606, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1957800000, 'incomeBeforeTaxRatio': 0.375, 'incomeTaxExpense': 401400000, 'netIncome': 1556400000, 'netIncomeRatio': 0.29811523138216367, 'eps': 6.68, 'epsdiluted': 6.64, 'weightedAverageShsOut': 223148000, 'weightedAverageShsOutDil': 224488000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312419000088/0000073124-19-000088-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312419000088/a201810-k.htm'}, {'date': '2017-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2018-02-27', 'acceptedDate': '2018-02-27 17:02:44', 'calendarYear': '2017', 'period': 'FY', 'revenue': 4706900000, 'costOfRevenue': 0, 'grossProfit': 4706900000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 2131100000, 'sellingAndMarketingExpenses': 95400000, 'sellingGeneralAndAdministrativeExpenses': 2226500000, 'otherExpenses': 1855500000, 'operatingExpenses': 4082000000, 'costAndExpenses': 0, 'interestIncome': 1769400000, 'interestExpense': 340200000, 'depreciationAndAmortization': 421700000, 'ebitda': 2395800000, 'ebitdaratio': 0.5089974293059126, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1633900000, 'incomeBeforeTaxRatio': 0.3471286834222099, 'incomeTaxExpense': 434900000, 'netIncome': 1199000000, 'netIncomeRatio': 0.25473241411544756, 'eps': 4.95, 'epsdiluted': 4.92, 'weightedAverageShsOut': 228258000, 'weightedAverageShsOutDil': 229654000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312418000141/0000073124-18-000141-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312418000141/a201710-k.htm'}, {'date': '2016-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2017-02-28', 'acceptedDate': '2017-02-27 21:25:26', 'calendarYear': '2016', 'period': 'FY', 'revenue': 4334700000, 'costOfRevenue': 0, 'grossProfit': 4334700000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1909100000, 'sellingAndMarketingExpenses': 83600000, 'sellingGeneralAndAdministrativeExpenses': 1992700000, 'otherExpenses': 1634300000, 'operatingExpenses': 3627000000, 'costAndExpenses': 0, 'interestIncome': 1416900000, 'interestExpense': 182000000, 'depreciationAndAmortization': 373300000, 'ebitda': 2072400000, 'ebitdaratio': 0.4780953699217939, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1517100000, 'incomeBeforeTaxRatio': 0.3499896186587307, 'incomeTaxExpense': 484600000, 'netIncome': 1032500000, 'netIncomeRatio': 0.23819410801208848, 'eps': 4.35, 'epsdiluted': 4.32, 'weightedAverageShsOut': 227581000, 'weightedAverageShsOutDil': 229151000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312417000117/0000073124-17-000117-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312417000117/a201610-k.htm'}, {'date': '2015-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2016-02-29', 'acceptedDate': '2016-02-29 16:57:00', 'calendarYear': '2015', 'period': 'FY', 'revenue': 4106900000, 'costOfRevenue': 0, 'grossProfit': 4106900000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1794300000, 'sellingAndMarketingExpenses': 93200000, 'sellingGeneralAndAdministrativeExpenses': 1887500000, 'otherExpenses': 1504500000, 'operatingExpenses': 3392000000, 'costAndExpenses': 0, 'interestIncome': 1224000000, 'interestExpense': 153900000, 'depreciationAndAmortization': 351600000, 'ebitda': 1970500000, 'ebitdaratio': 0.47980228396113855, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1465000000, 'incomeBeforeTaxRatio': 0.35671674499013856, 'incomeTaxExpense': 491200000, 'netIncome': 973800000, 'netIncomeRatio': 0.2371131510384962, 'eps': 4.03, 'epsdiluted': 3.99, 'weightedAverageShsOut': 232280000, 'weightedAverageShsOutDil': 234222000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000007312416000324/0000073124-16-000324-index.html', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000007312416000324/ntrs2015123110-k.htm'}, {'date': '2014-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2015-02-26', 'acceptedDate': '2015-02-26 17:04:56', 'calendarYear': '2014', 'period': 'FY', 'revenue': 3756600000, 'costOfRevenue': 0, 'grossProfit': 3756600000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1747700000, 'sellingAndMarketingExpenses': 88000000, 'sellingGeneralAndAdministrativeExpenses': 1835700000, 'otherExpenses': 1486300000, 'operatingExpenses': 3322000000, 'costAndExpenses': 0, 'interestIncome': 1186900000, 'interestExpense': 181400000, 'depreciationAndAmortization': 335700000, 'ebitda': 1707300000, 'ebitdaratio': 0.4544801149976042, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1190200000, 'incomeBeforeTaxRatio': 0.316829047542991, 'incomeTaxExpense': 378400000, 'netIncome': 811800000, 'netIncomeRatio': 0.21609966459032104, 'eps': 3.34, 'epsdiluted': 3.32, 'weightedAverageShsOut': 235830000, 'weightedAverageShsOutDil': 237720000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000119312515065963/d802907d10k.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000119312515065963/d802907d10k.htm'}, {'date': '2013-12-31', 'symbol': 'NTRS', 'reportedCurrency': 'USD', 'cik': '0000073124', 'fillingDate': '2014-02-26', 'acceptedDate': '2014-02-26 16:43:54', 'calendarYear': '2013', 'period': 'FY', 'revenue': 3525200000, 'costOfRevenue': 0, 'grossProfit': 3525200000, 'grossProfitRatio': 1, 'researchAndDevelopmentExpenses': 0, 'generalAndAdministrativeExpenses': 1626700000, 'sellingAndMarketingExpenses': 91600000, 'sellingGeneralAndAdministrativeExpenses': 1718300000, 'otherExpenses': 1517700000, 'operatingExpenses': 3236000000, 'costAndExpenses': 0, 'interestIncome': 1155500000, 'interestExpense': 222400000, 'depreciationAndAmortization': 318500000, 'ebitda': 1616400000, 'ebitdaratio': 0.4585271757630773, 'operatingIncome': 0, 'operatingIncomeRatio': 0, 'totalOtherIncomeExpensesNet': 0, 'incomeBeforeTax': 1075500000, 'incomeBeforeTaxRatio': 0.3050890729603994, 'incomeTaxExpense': 344200000, 'netIncome': 731300000, 'netIncomeRatio': 0.20744922273913538, 'eps': 3.01, 'epsdiluted': 2.99, 'weightedAverageShsOut': 239265000, 'weightedAverageShsOutDil': 240555000, 'link': 'https://www.sec.gov/Archives/edgar/data/73124/000119312514069870/d619551d10k.htm', 'finalLink': 'https://www.sec.gov/Archives/edgar/data/73124/000119312514069870/d619551d10k.htm'}]\n"
     ]
    }
   ],
   "source": [
    "incomeStatement = incomeStatement(apikey=apikey, symbol=symbol, limit=10)\n",
    "print(incomeStatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Filing Date</th>\n",
       "      <th>Accepted Date</th>\n",
       "      <th>Calendar Year</th>\n",
       "      <th>Period</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>Gross Profit Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Other Net Expenses</th>\n",
       "      <th>Income Before Tax</th>\n",
       "      <th>Income Before Tax Ratio</th>\n",
       "      <th>Income Tax Expenses</th>\n",
       "      <th>Net Income</th>\n",
       "      <th>Net Income Ratio</th>\n",
       "      <th>EPS</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Outstanding Shares</th>\n",
       "      <th>Diluted Outstanding Shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28 16:20:50</td>\n",
       "      <td>2022</td>\n",
       "      <td>FY</td>\n",
       "      <td>6761200000</td>\n",
       "      <td>0</td>\n",
       "      <td>6761200000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-496100000</td>\n",
       "      <td>1766300000</td>\n",
       "      <td>0.261241</td>\n",
       "      <td>430300000</td>\n",
       "      <td>1336000000</td>\n",
       "      <td>0.197598</td>\n",
       "      <td>6.16</td>\n",
       "      <td>6.14</td>\n",
       "      <td>208309331</td>\n",
       "      <td>208867264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>2022-02-28 16:35:35</td>\n",
       "      <td>2021</td>\n",
       "      <td>FY</td>\n",
       "      <td>6464500000</td>\n",
       "      <td>0</td>\n",
       "      <td>6464500000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2010100000</td>\n",
       "      <td>0.310944</td>\n",
       "      <td>464800000</td>\n",
       "      <td>1545300000</td>\n",
       "      <td>0.239044</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.14</td>\n",
       "      <td>208076000</td>\n",
       "      <td>208899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>2021-02-23 16:51:30</td>\n",
       "      <td>2020</td>\n",
       "      <td>FY</td>\n",
       "      <td>6100800000</td>\n",
       "      <td>0</td>\n",
       "      <td>6100800000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1627600000</td>\n",
       "      <td>0.266785</td>\n",
       "      <td>418300000</td>\n",
       "      <td>1209300000</td>\n",
       "      <td>0.198220</td>\n",
       "      <td>5.48</td>\n",
       "      <td>5.46</td>\n",
       "      <td>208319412</td>\n",
       "      <td>209007986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-02-25 17:06:15</td>\n",
       "      <td>2019</td>\n",
       "      <td>FY</td>\n",
       "      <td>6073100000</td>\n",
       "      <td>0</td>\n",
       "      <td>6073100000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1944100000</td>\n",
       "      <td>0.320117</td>\n",
       "      <td>451900000</td>\n",
       "      <td>1492200000</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>6.66</td>\n",
       "      <td>6.63</td>\n",
       "      <td>214525547</td>\n",
       "      <td>215601149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26 16:37:47</td>\n",
       "      <td>2018</td>\n",
       "      <td>FY</td>\n",
       "      <td>5220800000</td>\n",
       "      <td>0</td>\n",
       "      <td>5220800000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1957800000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>401400000</td>\n",
       "      <td>1556400000</td>\n",
       "      <td>0.298115</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.64</td>\n",
       "      <td>223148000</td>\n",
       "      <td>224488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>2018-02-27 17:02:44</td>\n",
       "      <td>2017</td>\n",
       "      <td>FY</td>\n",
       "      <td>4706900000</td>\n",
       "      <td>0</td>\n",
       "      <td>4706900000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1633900000</td>\n",
       "      <td>0.347129</td>\n",
       "      <td>434900000</td>\n",
       "      <td>1199000000</td>\n",
       "      <td>0.254732</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.92</td>\n",
       "      <td>228258000</td>\n",
       "      <td>229654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>2017-02-27 21:25:26</td>\n",
       "      <td>2016</td>\n",
       "      <td>FY</td>\n",
       "      <td>4334700000</td>\n",
       "      <td>0</td>\n",
       "      <td>4334700000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1517100000</td>\n",
       "      <td>0.349990</td>\n",
       "      <td>484600000</td>\n",
       "      <td>1032500000</td>\n",
       "      <td>0.238194</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.32</td>\n",
       "      <td>227581000</td>\n",
       "      <td>229151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>2016-02-29 16:57:00</td>\n",
       "      <td>2015</td>\n",
       "      <td>FY</td>\n",
       "      <td>4106900000</td>\n",
       "      <td>0</td>\n",
       "      <td>4106900000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1465000000</td>\n",
       "      <td>0.356717</td>\n",
       "      <td>491200000</td>\n",
       "      <td>973800000</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.99</td>\n",
       "      <td>232280000</td>\n",
       "      <td>234222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2015-02-26</td>\n",
       "      <td>2015-02-26 17:04:56</td>\n",
       "      <td>2014</td>\n",
       "      <td>FY</td>\n",
       "      <td>3756600000</td>\n",
       "      <td>0</td>\n",
       "      <td>3756600000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1190200000</td>\n",
       "      <td>0.316829</td>\n",
       "      <td>378400000</td>\n",
       "      <td>811800000</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.32</td>\n",
       "      <td>235830000</td>\n",
       "      <td>237720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>NTRS</td>\n",
       "      <td>2014-02-26</td>\n",
       "      <td>2014-02-26 16:43:54</td>\n",
       "      <td>2013</td>\n",
       "      <td>FY</td>\n",
       "      <td>3525200000</td>\n",
       "      <td>0</td>\n",
       "      <td>3525200000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1075500000</td>\n",
       "      <td>0.305089</td>\n",
       "      <td>344200000</td>\n",
       "      <td>731300000</td>\n",
       "      <td>0.207449</td>\n",
       "      <td>3.01</td>\n",
       "      <td>2.99</td>\n",
       "      <td>239265000</td>\n",
       "      <td>240555000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date symbol Filing Date        Accepted Date Calendar Year Period  \\\n",
       "0 2022-12-31   NTRS  2023-02-28  2023-02-28 16:20:50          2022     FY   \n",
       "1 2021-12-31   NTRS  2022-02-28  2022-02-28 16:35:35          2021     FY   \n",
       "2 2020-12-31   NTRS  2021-02-23  2021-02-23 16:51:30          2020     FY   \n",
       "3 2019-12-31   NTRS  2020-02-25  2020-02-25 17:06:15          2019     FY   \n",
       "4 2018-12-31   NTRS  2019-02-26  2019-02-26 16:37:47          2018     FY   \n",
       "5 2017-12-31   NTRS  2018-02-27  2018-02-27 17:02:44          2017     FY   \n",
       "6 2016-12-31   NTRS  2017-02-28  2017-02-27 21:25:26          2016     FY   \n",
       "7 2015-12-31   NTRS  2016-02-29  2016-02-29 16:57:00          2015     FY   \n",
       "8 2014-12-31   NTRS  2015-02-26  2015-02-26 17:04:56          2014     FY   \n",
       "9 2013-12-31   NTRS  2014-02-26  2014-02-26 16:43:54          2013     FY   \n",
       "\n",
       "      Revenue Cost of Revenue Gross Profit Gross Profit Ratio  ...  \\\n",
       "0  6761200000               0   6761200000                  1  ...   \n",
       "1  6464500000               0   6464500000                  1  ...   \n",
       "2  6100800000               0   6100800000                  1  ...   \n",
       "3  6073100000               0   6073100000                  1  ...   \n",
       "4  5220800000               0   5220800000                  1  ...   \n",
       "5  4706900000               0   4706900000                  1  ...   \n",
       "6  4334700000               0   4334700000                  1  ...   \n",
       "7  4106900000               0   4106900000                  1  ...   \n",
       "8  3756600000               0   3756600000                  1  ...   \n",
       "9  3525200000               0   3525200000                  1  ...   \n",
       "\n",
       "  Total Other Net Expenses Income Before Tax Income Before Tax Ratio  \\\n",
       "0               -496100000        1766300000                0.261241   \n",
       "1                        0        2010100000                0.310944   \n",
       "2                        0        1627600000                0.266785   \n",
       "3                        0        1944100000                0.320117   \n",
       "4                        0        1957800000                0.375000   \n",
       "5                        0        1633900000                0.347129   \n",
       "6                        0        1517100000                0.349990   \n",
       "7                        0        1465000000                0.356717   \n",
       "8                        0        1190200000                0.316829   \n",
       "9                        0        1075500000                0.305089   \n",
       "\n",
       "  Income Tax Expenses  Net Income Net Income Ratio   EPS Diluted EPS  \\\n",
       "0           430300000  1336000000         0.197598  6.16        6.14   \n",
       "1           464800000  1545300000         0.239044  7.16        7.14   \n",
       "2           418300000  1209300000         0.198220  5.48        5.46   \n",
       "3           451900000  1492200000         0.245706  6.66        6.63   \n",
       "4           401400000  1556400000         0.298115  6.68        6.64   \n",
       "5           434900000  1199000000         0.254732  4.95        4.92   \n",
       "6           484600000  1032500000         0.238194  4.35        4.32   \n",
       "7           491200000   973800000         0.237113  4.03        3.99   \n",
       "8           378400000   811800000         0.216100  3.34        3.32   \n",
       "9           344200000   731300000         0.207449  3.01        2.99   \n",
       "\n",
       "  Outstanding Shares Diluted Outstanding Shares  \n",
       "0          208309331                  208867264  \n",
       "1          208076000                  208899000  \n",
       "2          208319412                  209007986  \n",
       "3          214525547                  215601149  \n",
       "4          223148000                  224488000  \n",
       "5          228258000                  229654000  \n",
       "6          227581000                  229151000  \n",
       "7          232280000                  234222000  \n",
       "8          235830000                  237720000  \n",
       "9          239265000                  240555000  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomeStmtDf = pd.read_json(json.dumps(incomeStatement))\n",
    "incomeStmtDf = incomeStmtDf[['date', 'symbol', 'fillingDate',\n",
    "       'acceptedDate', 'calendarYear', 'period', 'revenue', 'costOfRevenue',\n",
    "       'grossProfit', 'grossProfitRatio', 'researchAndDevelopmentExpenses',\n",
    "       'generalAndAdministrativeExpenses', 'sellingAndMarketingExpenses',\n",
    "       'sellingGeneralAndAdministrativeExpenses', 'otherExpenses',\n",
    "       'operatingExpenses', 'costAndExpenses', 'interestIncome',\n",
    "       'interestExpense', 'depreciationAndAmortization', 'ebitda',\n",
    "       'ebitdaratio', 'operatingIncome', 'operatingIncomeRatio',\n",
    "       'totalOtherIncomeExpensesNet', 'incomeBeforeTax',\n",
    "       'incomeBeforeTaxRatio', 'incomeTaxExpense', 'netIncome',\n",
    "       'netIncomeRatio', 'eps', 'epsdiluted', 'weightedAverageShsOut',\n",
    "       'weightedAverageShsOutDil']]\n",
    "incomeStmtDf.columns = [['date', 'symbol', 'Filing Date',\n",
    "       'Accepted Date', 'Calendar Year', 'Period', 'Revenue', 'Cost of Revenue',\n",
    "       'Gross Profit', 'Gross Profit Ratio', 'R&D Expenses',\n",
    "       'General Adminstrative Expenses', 'Selling and Marketing Expenses',\n",
    "       'Selling General Administrative Expenses', 'Other Expenses',\n",
    "       'Operating Expenses', 'Cost and Expenses', 'Interest Income',\n",
    "       'Interest Expense', 'Depreciation & Amortization', 'EBITDA',\n",
    "       'EBITDA Ratio', 'Operating Income', 'Operating Income Ratio',\n",
    "       'Total Other Net Expenses', 'Income Before Tax',\n",
    "       'Income Before Tax Ratio', 'Income Tax Expenses', 'Net Income',\n",
    "       'Net Income Ratio', 'EPS', 'Diluted EPS', 'Outstanding Shares',\n",
    "       'Diluted Outstanding Shares']]\n",
    "incomeStmtDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletePibData(SearchService, SearchKey, pibIndexName, \"51143\", \"1\", returnFields=['id', 'symbol', 'cik', 'step', 'description', 'insertedDate',\n",
    "#                                                                       'pibData'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PROMPT_PREFIX = \"\"\"\n",
    "First set the pandas display options to show all the columns, get the column names, then answer the question.\n",
    "\"\"\"\n",
    "\n",
    "CSV_PROMPT_SUFFIX = \"\"\"\n",
    "- **ALWAYS** before giving the Final Answer, try another method. Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question. If you are not sure, try another method.\n",
    "- If the methods tried do not give the same result, reflect and try again until you have two methods that have the same result. \n",
    "- If you still cannot arrive to a consistent result, say that you are not sure of the answer.\n",
    "- If you are sure of the correct answer, create a beautiful and thorough response using Markdown.\n",
    "- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**. \n",
    "- **ALWAYS**, as part of your \"Final Answer\", explain how you got to the answer on a section that starts with: \"\\n\\nExplanation:\\n\". In the explanation, mention the column names that you used to get to the final answer. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to filter the dataframe to only include rows where the 'Calendar Year' column is 2022, and then sum the 'Revenue' column.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df[df[('Calendar Year',)] == 2022]['Revenue'].sum()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRevenue    6761200000\n",
      "dtype: int64\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe total revenue for the year 2022 is 6,761,200,000.\n",
      "\n",
      "Final Answer: 6,761,200,000\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "6,761,200,000\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "\n",
    "agent = create_pandas_dataframe_agent(llmChat,df=incomeStmtDf, verbose=True)\n",
    "\n",
    "Question = 'What is the total revenue for the year 2022?'\n",
    "#Question = 'How much did revenue increased in 2022 in comparision to 2021?'\n",
    "response = agent.run(Question) \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
